{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 04:56:10.887626: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-26 04:56:10.983770: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-26 04:56:11.692090: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-26 04:56:11.695559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-26 04:56:13.239875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras_core as keras\n",
    "from keras_core import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromax import Simulator, sample_data\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_means_and_variances(dataframes):\n",
    "    # Calculate the mean and variance for each dataframe\n",
    "    mean_values = [df.mean() for df in dataframes]\n",
    "    var_values = [df.var() for df in dataframes]\n",
    "    var_values = np.array(var_values).flatten()\n",
    "    mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "    # Create an array for the x-values\n",
    "    x_values = range(len(dataframes))\n",
    "\n",
    "    # Create the scatter plot with error bars\n",
    "    plt.errorbar(x_values, mean_values, yerr=var_values, fmt='o')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_genetic_map(n_markers, n_chromosomes):\n",
    "  df = pd.DataFrame(generate_marker_effects(n_markers=n_markers), columns=['Yield'])\n",
    "  df['cM'] = np.random.uniform(0, 200, len(df))\n",
    "  df['CHR.PHYS'] = '1A'\n",
    "  df = df.sort_values(by='cM')\n",
    "  df = df[['CHR.PHYS', 'cM', 'Yield']]\n",
    "  # save df as csv under filename\n",
    "  return df\n",
    "\n",
    "def generate_population(n_pop=100, n_markers=500):\n",
    "    \"\"\"\n",
    "    Generate a numpy array of randoms of length 500 with randomized 0, 1, or 2 at each position.\n",
    "    It will generate 100 individuals based on n_pop.\n",
    "\n",
    "    Returns: numpy array of size (n_pop, n_markers)\n",
    "    \"\"\"\n",
    "    shape=(n_pop, n_markers, 2)\n",
    "    # Define the elements to choose from and their associated probabilities\n",
    "    elements = [0, 1, 2]\n",
    "    probabilities = [1/3, 1/3, 1/3]  # equal probabilities for 0, 1, and 2\n",
    "\n",
    "    # Generate the population\n",
    "    population = np.random.choice(elements, size=(n_pop, n_markers), p=probabilities)\n",
    "\n",
    "    return np.random.choice([True, False], size=shape)\n",
    "\n",
    "\n",
    "def generate_marker_effects(n_markers=500, mu=0, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Generate a numpy array of marker effects with a normal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    n_markers (int): Number of markers.\n",
    "    mu (float): Mean of the distribution.\n",
    "    sigma (float): Standard deviation of the distribution.\n",
    "\n",
    "    Returns:\n",
    "    numpy array of marker effects\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the marker effects\n",
    "    marker_effects = np.random.normal(mu, sigma, n_markers)\n",
    "\n",
    "    return marker_effects\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def select_random_individuals(arr, num_individuals):\n",
    "    # Get the shape of the array\n",
    "    shape = arr.shape\n",
    "\n",
    "    # Generate random indices along the first axis\n",
    "    idx = np.random.choice(shape[0], size=num_individuals)\n",
    "\n",
    "    # Select the random individuals\n",
    "\n",
    "    return random_individuals\n",
    "\n",
    "def select_mixed(population, random_split=.99):\n",
    "  n_pop = population.shape[0]\n",
    "\n",
    "  n_random = int(n_pop * random_split)\n",
    "  n_select = int(n_pop * (1-random_split))\n",
    "\n",
    "  random_parents = select_random_individuals(Farm.current_population, n_random)\n",
    "  selected_parents = Farm.Simulator.select(Farm.current_population, k = n_select)\n",
    "  combined_arr = np.concatenate((random_parents, selected_parents), axis=0)\n",
    "  return combined_arr\n",
    "\n",
    "def plot_replicate_means_and_variances(replicate_data, start_index=None, end_index=None):\n",
    "    # Create a new figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # If start_index or end_index is not provided, set them to default values\n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if end_index is None:\n",
    "        end_index = len(replicate_data[0])\n",
    "\n",
    "    # For each list of dataframes in replicate_data\n",
    "    for i, dataframes in enumerate(replicate_data):\n",
    "        # Select the dataframes in the specified range\n",
    "        dataframes = dataframes[start_index:end_index]\n",
    "\n",
    "        # Calculate the mean and variance for each dataframe\n",
    "        mean_values = [df.mean() for df in dataframes]\n",
    "        var_values = [df.var() for df in dataframes]\n",
    "\n",
    "        # Flatten the var_values and mean_values lists to 1D arrays\n",
    "        var_values = np.array(var_values).flatten()\n",
    "        mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "        # Create an array for the x-values\n",
    "        x_values = range(len(dataframes))\n",
    "\n",
    "        # Plot the means with error bars for the variances\n",
    "        ax.errorbar(x_values, mean_values, yerr=var_values, fmt='o', label=f'Replicate {i+1}')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_replicate_means(replicate_data):\n",
    "    # Create a new figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # For each list of dataframes in replicate_data\n",
    "    for i, dataframes in enumerate(replicate_data):\n",
    "        # Calculate the mean for each dataframe\n",
    "        mean_values = [df.mean() for df in dataframes]\n",
    "        # Flatten the mean_values list to a 1D array\n",
    "        mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "        # Create an array for the x-values\n",
    "        x_values = range(len(dataframes))\n",
    "\n",
    "        # Plot the means as a line plot\n",
    "        ax.plot(x_values, mean_values, label=f'Replicate {i+1}')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def parse_markerEffects(genetic_map, nChr):\n",
    "    # Get the length of the genetic map\n",
    "    length = len(genetic_map)\n",
    "\n",
    "    # Create a new array for storing the chromosome number for each marker\n",
    "    chr = [0] * length\n",
    "\n",
    "    # Calculate the number of markers per chromosome\n",
    "    markers_per_chr = length // nChr\n",
    "\n",
    "    # Iterate over the range of the genetic map length\n",
    "    for i in range(length):\n",
    "        # Calculate the chromosome number and store it in the chr array\n",
    "        chr[i] = i // markers_per_chr + 1\n",
    "\n",
    "    return chr\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "def score_top(scores: pd.DataFrame, column: str, k: int):\n",
    "    # Sort the DataFrame from high to low\n",
    "    sorted_scores = scores.sort_values(by=column, ascending=False)\n",
    "    # Get the top K indexes\n",
    "    top_k_indexes = sorted_scores.head(k).index\n",
    "    return top_k_indexes\n",
    "\n",
    "\n",
    "def score_top_percentile(scores: pd.DataFrame, column: str, percentile_min: float, percentile_max: float, k: int):\n",
    "    # Ensure max percentile is greater than min percentile\n",
    "    assert percentile_max > percentile_min, \"Error: max percentile should be greater than min percentile\"\n",
    "    \n",
    "    # Calculate the percentiles\n",
    "    lower = scores[column].quantile(percentile_min)\n",
    "    upper = scores[column].quantile(percentile_max)\n",
    "    # Filter the DataFrame\n",
    "    filtered_scores = scores[(scores[column] >= lower) & (scores[column] <= upper)]\n",
    "    # Sample k random indexes\n",
    "    sampled_indexes = np.random.choice(filtered_scores.index, k, replace=True)\n",
    "\n",
    "    return sampled_indexes\n",
    "\n",
    "def reshape_pop(maizeHaplo):\n",
    "    reshapeHaplo = maizeHaplo.reshape(int((maizeHaplo.shape[0])/2),2,maizeHaplo.shape[1])\n",
    "    reshapeHaplo = reshapeHaplo.transpose((0,2,1))\n",
    "    return reshapeHaplo\n",
    "\n",
    "def return_genetic_map_df(markerEffects, nChr, geneticMap):\n",
    "    chr = parse_markerEffects(markerEffects, nChr)\n",
    "    chr = [int(x[0]) for x in chr]\n",
    "    trait = markerEffects\n",
    "    pos = geneticMap\n",
    "    # Assuming chr, trait, pos are your arrays\n",
    "    df = pd.DataFrame({'CHR.PHYS': chr, 'Yield': trait, 'cM': pos})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "In (function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,  :\n",
       "  libraries ‘/usr/local/lib/R/site-library’, ‘/usr/lib/R/site-library’ contain no packages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "x <- seq(0, 2*pi, length.out=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.12822827, 0.25645654, 0.38468481, 0.51291309,\n",
       "       0.64114136, 0.76936963, 0.8975979 , 1.02582617, 1.15405444,\n",
       "       1.28228272, 1.41051099, 1.53873926, 1.66696753, 1.7951958 ,\n",
       "       1.92342407, 2.05165235, 2.17988062, 2.30810889, 2.43633716,\n",
       "       2.56456543, 2.6927937 , 2.82102197, 2.94925025, 3.07747852,\n",
       "       3.20570679, 3.33393506, 3.46216333, 3.5903916 , 3.71861988,\n",
       "       3.84684815, 3.97507642, 4.10330469, 4.23153296, 4.35976123,\n",
       "       4.48798951, 4.61621778, 4.74444605, 4.87267432, 5.00090259,\n",
       "       5.12913086, 5.25735913, 5.38558741, 5.51381568, 5.64204395,\n",
       "       5.77027222, 5.89850049, 6.02672876, 6.15495704, 6.28318531])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %R install.packages(\"AlphaSimR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading required package: R6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(\"AlphaSimR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "nInd = 50\n",
    "nChr = 3\n",
    "segSites = 10\n",
    "\n",
    "founderGenomes = runMacs(nInd = nInd,\n",
    "                         nChr = nChr,\n",
    "                         segSites = segSites,\n",
    "                         species = \"MAIZE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "SP = SimParam$new(founderGenomes)\n",
    "SP$addTraitA(segSites)\n",
    "# SP$setVarE(h2=.02)\n",
    "pop = newPop(founderGenomes, simParam=SP)\n",
    "ans = fastRRBLUP(pop, simParam=SP, useQtl=TRUE, use='gv')\n",
    "ans@gv[[1]]@addEff\n",
    "markerEffects = slot(slot(ans, \"gv\")[[1]], \"addEff\")\n",
    "maizeHaplo = pullSegSiteHaplo(pop)\n",
    "maizeGeno = pullSegSiteGeno(pop)\n",
    "#cm positions of each marker\n",
    "genMap = SP$genMap\n",
    "geneticMap = unlist(genMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o maizeHaplo\n",
    "%R -o maizeGeno\n",
    "%R -o markerEffects\n",
    "%R -o geneticMap\n",
    "%R -o nInd\n",
    "%R -o nChr\n",
    "%R -o segSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreedingProgram:\n",
    "    \"\"\"\n",
    "    Represents a breeding program with a PPO agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial_population, genetic_map, population_size, marker_count, chromosome_number, max_generation, heritability):\n",
    "        \"\"\"\n",
    "        Initializes the breeding program.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the basic attributes\n",
    "        self.population_size = population_size\n",
    "        self.marker_count = marker_count\n",
    "        self.initial_population = initial_population\n",
    "        self.genetic_map = genetic_map\n",
    "        self.max_generation = max_generation\n",
    "\n",
    "        # Initialize the simulator\n",
    "        self.simulator = Simulator(genetic_map=self.genetic_map, h2=heritability)\n",
    "        self.simulator.load_population('mypop.npy')\n",
    "\n",
    "        # Initialize the current generation and history\n",
    "        self.current_generation = 0\n",
    "        self.history = []\n",
    "\n",
    "        # Start the breeding program\n",
    "        self._start_breeding_program()\n",
    "        \n",
    "    def _start_breeding_program(self):\n",
    "        \"\"\"\n",
    "        Starts the breeding program.\n",
    "        \"\"\"\n",
    "        self.current_population = self.initial_population\n",
    "        self.current_scores = self.simulator.GEBV(reshape_pop(self.initial_population))\n",
    "        self.history.append(self.current_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "initial_population = maizeGeno \n",
    "genetic_map = return_genetic_map_df(markerEffects, nChr, geneticMap)\n",
    "reshapeHaplo = reshape_pop(maizeHaplo)\n",
    "np.save('mypop', reshapeHaplo)\n",
    "\n",
    "\n",
    "population_size = int(nInd)\n",
    "marker_count = int((segSites * nChr))\n",
    "chromosome_number = int(nChr)\n",
    "generation_max = 10\n",
    "heritability = .5\n",
    "\n",
    "x = BreedingProgram(initial_population, genetic_map, population_size, marker_count, chromosome_number, generation_max, heritability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysim =  Simulator(genetic_map=genetic_map, h2=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "\n",
    "#create init population + genetic map\n",
    "n = int(nInd)\n",
    "m = int((segSites * nChr))\n",
    "\n",
    "# Define the actor model\n",
    "actor_input = keras.layers.Input(shape=(n, m))\n",
    "x = keras.layers.Dense(64, activation='relu')(actor_input)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "actor_output = keras.layers.Dense(n*2, activation='softmax')(x)\n",
    "actor_model = keras.models.Model(actor_input, actor_output)\n",
    "actor_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Define the critic model\n",
    "critic_input1 = keras.layers.Input(shape=(50, 30))\n",
    "critic_input2 = keras.layers.Input(shape=(50, 100))\n",
    "\n",
    "x1 = keras.layers.Dense(64, activation='relu')(critic_input1)\n",
    "x2 = keras.layers.Dense(64, activation='relu')(critic_input2)\n",
    "\n",
    "combined = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "x3 = keras.layers.Dense(64, activation='relu')(combined)\n",
    "critic_output = keras.layers.Dense(1, activation='linear')(x3)\n",
    "\n",
    "critic_model = keras.models.Model([critic_input1, critic_input2], critic_output)\n",
    "critic_model.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "[[[ 0.0730167 ]\n",
      "  [ 0.20809555]\n",
      "  [ 0.07448385]\n",
      "  [-0.09126396]\n",
      "  [ 0.00086595]\n",
      "  [-0.21957588]\n",
      "  [ 0.1435154 ]\n",
      "  [ 0.11126265]\n",
      "  [ 0.05090525]\n",
      "  [ 0.09278551]\n",
      "  [ 0.23796186]\n",
      "  [ 0.02201348]\n",
      "  [-0.0615964 ]\n",
      "  [ 0.19914946]\n",
      "  [ 0.1463851 ]\n",
      "  [ 0.14326441]\n",
      "  [ 0.02544205]\n",
      "  [ 0.06061251]\n",
      "  [ 0.05234013]\n",
      "  [ 0.10652588]\n",
      "  [ 0.22468287]\n",
      "  [ 0.08473157]\n",
      "  [ 0.08448701]\n",
      "  [ 0.01135324]\n",
      "  [-0.04238733]\n",
      "  [ 0.18568572]\n",
      "  [ 0.0828736 ]\n",
      "  [ 0.1916794 ]\n",
      "  [ 0.1160223 ]\n",
      "  [ 0.02935174]\n",
      "  [ 0.01972546]\n",
      "  [ 0.06758972]\n",
      "  [ 0.07147934]\n",
      "  [ 0.13588998]\n",
      "  [ 0.22061916]\n",
      "  [ 0.12644088]\n",
      "  [ 0.04400939]\n",
      "  [-0.04747585]\n",
      "  [ 0.10367161]\n",
      "  [ 0.0844464 ]\n",
      "  [ 0.13830872]\n",
      "  [ 0.21994741]\n",
      "  [ 0.0273559 ]\n",
      "  [-0.10807846]\n",
      "  [ 0.18025626]\n",
      "  [-0.06085896]\n",
      "  [ 0.10714634]\n",
      "  [ 0.02967161]\n",
      "  [ 0.10505256]\n",
      "  [ 0.00176729]]]\n"
     ]
    }
   ],
   "source": [
    "# Ensure your inputs are numpy arrays and have the right shape\n",
    "example_population = example_population\n",
    "action_probabilities = action_probabilities\n",
    "\n",
    "# Predict\n",
    "output = critic_model.predict([ example_population, action_probabilities])\n",
    "\n",
    "# Print the output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "actor model output : (1, 50, 100)\n",
      "example population shape, single sample : (1, 50, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a random example\n",
    "example_population = np.random.rand(1, n, m)\n",
    "# Send the example through the actor network\n",
    "action_probabilities = actor_model.predict(example_population)\n",
    "print(f'actor model output : {action_probabilities.shape}')\n",
    "print(f'example population shape, single sample : {example_population.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 5000)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m action_probabilities_reshaped \u001b[38;5;241m=\u001b[39m action_probabilities\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcritic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexample_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_probabilities_reshaped\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileeig14pok.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/glect/breeder_agent/agent_env/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 5000)\n"
     ]
    }
   ],
   "source": [
    "action_probabilities_reshaped = action_probabilities.reshape(1, -1)\n",
    "critic_model.predict([example_population, action_probabilities_reshaped])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
