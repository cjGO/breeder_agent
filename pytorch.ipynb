{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 12:41:05.126217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromax import Simulator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"pytorch\"\n",
    "import matplotlib\n",
    "from jax import device_get\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_means_and_variances(dataframes):\n",
    "    # Calculate the mean and variance for each dataframe\n",
    "    mean_values = [df.mean() for df in dataframes]\n",
    "    var_values = [df.var() for df in dataframes]\n",
    "    var_values = np.array(var_values).flatten()\n",
    "    mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "    # Create an array for the x-values\n",
    "    x_values = range(len(dataframes))\n",
    "\n",
    "    # Create the scatter plot with error bars\n",
    "    plt.errorbar(x_values, mean_values, yerr=var_values, fmt='o')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_genetic_map(n_markers, n_chromosomes):\n",
    "  df = pd.DataFrame(generate_marker_effects(n_markers=n_markers), columns=['Yield'])\n",
    "  df['cM'] = np.random.uniform(0, 200, len(df))\n",
    "  df['CHR.PHYS'] = '1A'\n",
    "  df = df.sort_values(by='cM')\n",
    "  df = df[['CHR.PHYS', 'cM', 'Yield']]\n",
    "  # save df as csv under filename\n",
    "  return df\n",
    "\n",
    "def generate_population(n_pop=100, n_markers=500):\n",
    "    \"\"\"\n",
    "    Generate a numpy array of randoms of length 500 with randomized 0, 1, or 2 at each position.\n",
    "    It will generate 100 individuals based on n_pop.\n",
    "\n",
    "    Returns: numpy array of size (n_pop, n_markers)\n",
    "    \"\"\"\n",
    "    shape=(n_pop, n_markers, 2)\n",
    "    # Define the elements to choose from and their associated probabilities\n",
    "    elements = [0, 1, 2]\n",
    "    probabilities = [1/3, 1/3, 1/3]  # equal probabilities for 0, 1, and 2\n",
    "\n",
    "    # Generate the population\n",
    "    population = np.random.choice(elements, size=(n_pop, n_markers), p=probabilities)\n",
    "\n",
    "    return np.random.choice([True, False], size=shape)\n",
    "\n",
    "\n",
    "def generate_marker_effects(n_markers=500, mu=0, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Generate a numpy array of marker effects with a normal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    n_markers (int): Number of markers.\n",
    "    mu (float): Mean of the distribution.\n",
    "    sigma (float): Standard deviation of the distribution.\n",
    "\n",
    "    Returns:\n",
    "    numpy array of marker effects\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the marker effects\n",
    "    marker_effects = np.random.normal(mu, sigma, n_markers)\n",
    "\n",
    "    return marker_effects\n",
    "\n",
    "\n",
    "def select_random_individuals(arr, num_individuals):\n",
    "    # Get the shape of the array\n",
    "    shape = arr.shape\n",
    "\n",
    "    # Generate random indices along the first axis\n",
    "    idx = np.random.choice(shape[0], size=num_individuals)\n",
    "\n",
    "    # Select the random individuals\n",
    "\n",
    "    return random_individuals\n",
    "\n",
    "def select_mixed(population, random_split=.99):\n",
    "  n_pop = population.shape[0]\n",
    "\n",
    "  n_random = int(n_pop * random_split)\n",
    "  n_select = int(n_pop * (1-random_split))\n",
    "\n",
    "  random_parents = select_random_individuals(Farm.current_population, n_random)\n",
    "  selected_parents = Farm.Simulator.select(Farm.current_population, k = n_select)\n",
    "  combined_arr = np.concatenate((random_parents, selected_parents), axis=0)\n",
    "  return combined_arr\n",
    "\n",
    "def plot_replicate_means_and_variances(replicate_data, start_index=None, end_index=None):\n",
    "    # Create a new figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # If start_index or end_index is not provided, set them to default values\n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if end_index is None:\n",
    "        end_index = len(replicate_data[0])\n",
    "\n",
    "    # For each list of dataframes in replicate_data\n",
    "    for i, dataframes in enumerate(replicate_data):\n",
    "        # Select the dataframes in the specified range\n",
    "        dataframes = dataframes[start_index:end_index]\n",
    "\n",
    "        # Calculate the mean and variance for each dataframe\n",
    "        mean_values = [df.mean() for df in dataframes]\n",
    "        var_values = [df.var() for df in dataframes]\n",
    "\n",
    "        # Flatten the var_values and mean_values lists to 1D arrays\n",
    "        var_values = np.array(var_values).flatten()\n",
    "        mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "        # Create an array for the x-values\n",
    "        x_values = range(len(dataframes))\n",
    "\n",
    "        # Plot the means with error bars for the variances\n",
    "        ax.errorbar(x_values, mean_values, yerr=var_values, fmt='o', label=f'Replicate {i+1}')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_replicate_means(replicate_data):\n",
    "    # Create a new figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # For each list of dataframes in replicate_data\n",
    "    for i, dataframes in enumerate(replicate_data):\n",
    "        # Calculate the mean for each dataframe\n",
    "        mean_values = [df.mean() for df in dataframes]\n",
    "        # Flatten the mean_values list to a 1D array\n",
    "        mean_values = np.array(mean_values).flatten()\n",
    "\n",
    "        # Create an array for the x-values\n",
    "        x_values = range(len(dataframes))\n",
    "\n",
    "        # Plot the means as a line plot\n",
    "        ax.plot(x_values, mean_values, label=f'Replicate {i+1}')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def parse_markerEffects(genetic_map, nChr):\n",
    "    # Get the length of the genetic map\n",
    "    length = len(genetic_map)\n",
    "\n",
    "    # Create a new array for storing the chromosome number for each marker\n",
    "    chr = [0] * length\n",
    "\n",
    "    # Calculate the number of markers per chromosome\n",
    "    markers_per_chr = length // nChr\n",
    "\n",
    "    # Iterate over the range of the genetic map length\n",
    "    for i in range(length):\n",
    "        # Calculate the chromosome number and store it in the chr array\n",
    "        chr[i] = i // markers_per_chr + 1\n",
    "\n",
    "    return chr\n",
    "\n",
    "def score_top(scores: pd.DataFrame, column: str, k: int):\n",
    "    # Sort the DataFrame from high to low\n",
    "    sorted_scores = scores.sort_values(by=column, ascending=False)\n",
    "    # Get the top K indexes\n",
    "    top_k_indexes = sorted_scores.head(k).index\n",
    "    return top_k_indexes\n",
    "\n",
    "\n",
    "def score_top_percentile(scores: pd.DataFrame, column: str, percentile_min: float, percentile_max: float, k: int):\n",
    "    # Ensure max percentile is greater than min percentile\n",
    "    assert percentile_max > percentile_min, \"Error: max percentile should be greater than min percentile\"\n",
    "    \n",
    "    # Calculate the percentiles\n",
    "    lower = scores[column].quantile(percentile_min)\n",
    "    upper = scores[column].quantile(percentile_max)\n",
    "    # Filter the DataFrame\n",
    "    filtered_scores = scores[(scores[column] >= lower) & (scores[column] <= upper)]\n",
    "    # Sample k random indexes\n",
    "    sampled_indexes = np.random.choice(filtered_scores.index, k, replace=True)\n",
    "\n",
    "    return sampled_indexes\n",
    "\n",
    "def reshape_pop(maizeHaplo):\n",
    "    reshapeHaplo = maizeHaplo.reshape(int((maizeHaplo.shape[0])/2),2,maizeHaplo.shape[1])\n",
    "    reshapeHaplo = reshapeHaplo.transpose((0,2,1))\n",
    "    return reshapeHaplo\n",
    "\n",
    "def return_genetic_map_df(markerEffects, nChr, geneticMap):\n",
    "    chr = parse_markerEffects(markerEffects, nChr)\n",
    "    chr = [int(x[0]) for x in chr]\n",
    "    trait = markerEffects\n",
    "    pos = geneticMap\n",
    "    # Assuming chr, trait, pos are your arrays\n",
    "    df = pd.DataFrame({'CHR.PHYS': chr, 'Yield': trait, 'cM': pos})\n",
    "    return df\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(ax, probabilities, label=None, color=None):\n",
    "    ax.hist(probabilities, bins='auto', density=True, alpha=0.5, label=label, color=color)\n",
    "    ax.set_title('Probability Distribution')\n",
    "    ax.set_xlabel('Probability')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "def plot_bar(ax, probabilities, label=None, color=None):\n",
    "    indices = range(len(probabilities))\n",
    "    ax.bar(indices, probabilities, alpha=0.5, label=label, color=color)\n",
    "    ax.set_title('Probability per Index')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Probability')\n",
    "\n",
    "def plot_probabilities(probabilities1, probabilities2):\n",
    "    # Create subplots: 1 row, 2 columns\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Call the plot functions for the first set of probabilities\n",
    "    plot_histogram(axs[0], probabilities1, label='Probabilities 1', color='blue')\n",
    "    plot_bar(axs[1], probabilities1, label='Probabilities 1', color='blue')\n",
    "\n",
    "    # Call the plot functions for the second set of probabilities\n",
    "    plot_histogram(axs[0], probabilities2, label='Probabilities 2', color='red')\n",
    "    plot_bar(axs[1], probabilities2, label='Probabilities 2', color='red')\n",
    "\n",
    "    # Add legends\n",
    "    axs[0].legend(loc='upper right')\n",
    "    axs[1].legend(loc='upper right')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()  # Adjusts subplot params so that subplots fit in the figure area\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "In (function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,  :\n",
       "  libraries ‘/usr/local/lib/R/site-library’, ‘/usr/lib/R/site-library’ contain no packages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "x <- seq(0, 2*pi, length.out=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.12822827, 0.25645654, 0.38468481, 0.51291309,\n",
       "       0.64114136, 0.76936963, 0.8975979 , 1.02582617, 1.15405444,\n",
       "       1.28228272, 1.41051099, 1.53873926, 1.66696753, 1.7951958 ,\n",
       "       1.92342407, 2.05165235, 2.17988062, 2.30810889, 2.43633716,\n",
       "       2.56456543, 2.6927937 , 2.82102197, 2.94925025, 3.07747852,\n",
       "       3.20570679, 3.33393506, 3.46216333, 3.5903916 , 3.71861988,\n",
       "       3.84684815, 3.97507642, 4.10330469, 4.23153296, 4.35976123,\n",
       "       4.48798951, 4.61621778, 4.74444605, 4.87267432, 5.00090259,\n",
       "       5.12913086, 5.25735913, 5.38558741, 5.51381568, 5.64204395,\n",
       "       5.77027222, 5.89850049, 6.02672876, 6.15495704, 6.28318531])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %R install.packages(\"AlphaSimR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading required package: R6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(\"AlphaSimR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "nInd = 10\n",
    "nChr = 2\n",
    "segSites = 5\n",
    "\n",
    "founderGenomes = runMacs(nInd = nInd,\n",
    "                         nChr = nChr,\n",
    "                         segSites = segSites,\n",
    "                         species = \"MAIZE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "SP = SimParam$new(founderGenomes)\n",
    "SP$addTraitA(segSites)\n",
    "# SP$setVarE(h2=.02)\n",
    "pop = newPop(founderGenomes, simParam=SP)\n",
    "ans = fastRRBLUP(pop, simParam=SP, useQtl=TRUE, use='gv')\n",
    "ans@gv[[1]]@addEff\n",
    "markerEffects = slot(slot(ans, \"gv\")[[1]], \"addEff\")\n",
    "maizeHaplo = pullSegSiteHaplo(pop)\n",
    "maizeGeno = pullSegSiteGeno(pop)\n",
    "#cm positions of each marker\n",
    "genMap = SP$genMap\n",
    "geneticMap = unlist(genMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o maizeHaplo\n",
    "%R -o maizeGeno\n",
    "%R -o markerEffects\n",
    "%R -o geneticMap\n",
    "%R -o nInd\n",
    "%R -o nChr\n",
    "%R -o segSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMarkers = segSites * nChr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import random\n",
    "\n",
    "def simplify_geneticmap(lst, qtl):\n",
    "    # Select 'qtl' random indexes\n",
    "    indexes_positive = random.sample(range(len(lst)), qtl)\n",
    "    \n",
    "    # Select 'qtl' random indexes not already selected\n",
    "    remaining_indexes = set(range(len(lst))) - set(indexes_positive)\n",
    "    indexes_negative = random.sample(remaining_indexes, qtl)\n",
    "\n",
    "    # Modify the list\n",
    "    for i in range(len(lst)):\n",
    "        if i in indexes_positive:\n",
    "            lst[i] = random.uniform(0.5, 1.0)  # Assign random float between 0.5 and 1.0\n",
    "        elif i in indexes_negative:\n",
    "            lst[i] = random.uniform(-0.5, -1.0)  # Assign random float between -0.5 and -1.0\n",
    "        else:\n",
    "            lst[i] = 0  # Assign 0\n",
    "\n",
    "    return lst\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the numpy array from the specified file path.\n",
    "    \"\"\"\n",
    "    return np.load(file_path)\n",
    "\n",
    "def sum_ploidy_values(data):\n",
    "    \"\"\"\n",
    "    Sum the ploidy values in the data.\n",
    "    \"\"\"\n",
    "    return np.sum(data, axis=2)\n",
    "\n",
    "def create_heatmap(data, title=\"Heatmap of Ploidy Values\", xlabel=\"Marker Index\", ylabel=\"Individual Index\"):\n",
    "    \"\"\"\n",
    "    Create a heatmap from the provided data.\n",
    "    \"\"\"\n",
    "    # Choosing a visually appealing color scheme\n",
    "    cmap = sns.color_palette([\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"], as_cmap=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = sns.heatmap(data, cmap=cmap, cbar=False)\n",
    "\n",
    "    # Creating a color bar manually\n",
    "    cbar = ax.figure.colorbar(ax.collections[0])\n",
    "    cbar.set_ticks([0.33, 1, 1.67])\n",
    "    cbar.set_ticklabels(['0', '1', '2'])\n",
    "    cbar.set_label('Summed Ploidy Value')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population_heatmap(ax, population_data, marker_strength):\n",
    "    summed_data = np.sum(population_data, axis=2)\n",
    "    cmap = sns.color_palette([\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"])\n",
    "    strength_cmap = matplotlib.colormaps.get_cmap('RdYlGn')  # Updated line\n",
    "    sns.heatmap(summed_data, cmap=cmap, cbar_kws={'ticks': [0, 1, 2]}, ax=ax)\n",
    "\n",
    "    ax.set_xticks(np.arange(population_data.shape[1]) + 0.5)\n",
    "    marker_labels = [f'{i+1}' for i in range(population_data.shape[1])]\n",
    "    ax.set_xticklabels(marker_labels, rotation=0, ha='center')\n",
    "\n",
    "    for tick_label, strength in zip(ax.get_xticklabels(), marker_strength):\n",
    "        tick_label.set_backgroundcolor(strength_cmap((strength + 1) / 2))  # Normalize and map the strength value\n",
    "        tick_label.set_color('white')\n",
    "        tick_label.set_fontweight('bold')\n",
    "        tick_label.set_bbox(dict(facecolor=strength_cmap((strength + 1) / 2), edgecolor='none', boxstyle='round,pad=0.3'))\n",
    "\n",
    "    ax.set_title(\"Heatmap of Population Genotype Dosages\")\n",
    "    ax.set_xlabel(\"Markers\")\n",
    "    ax.set_ylabel(\"Individuals\")\n",
    "\n",
    "def plot_allele_frequencies(ax, data, marker_strength, sort_by_allele_0=False, bar_width=0.8):\n",
    "    allele_counts = np.apply_along_axis(lambda x: np.bincount(x, minlength=3), axis=2, arr=data)\n",
    "    total_allele_counts = allele_counts.sum(axis=0)\n",
    "    allele_frequencies = total_allele_counts / total_allele_counts.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    allele_0_proportions = allele_frequencies[:, 0]\n",
    "    allele_1_proportions = allele_frequencies[:, 1]\n",
    "    x_positions = np.arange(1, len(allele_0_proportions) + 1)\n",
    "    normalized_strength = (np.array(marker_strength) + 1) / 2\n",
    "\n",
    "    cmap = plt.cm.RdYlGn\n",
    "\n",
    "    if sort_by_allele_0:\n",
    "        sorted_indices = np.argsort(-allele_0_proportions)\n",
    "        allele_0_proportions = allele_0_proportions[sorted_indices]\n",
    "        allele_1_proportions = allele_1_proportions[sorted_indices]\n",
    "        normalized_strength = normalized_strength[sorted_indices]\n",
    "\n",
    "    for xpos, a0, a1, strength in zip(x_positions, allele_0_proportions, allele_1_proportions, normalized_strength):\n",
    "        ax.bar(xpos, a0, color='red', edgecolor='black', width=bar_width, label='Allele 0' if xpos == 1 else \"\")\n",
    "        ax.bar(xpos, a1, bottom=a0, color='black', edgecolor='black', width=bar_width, label='Allele 1' if xpos == 1 else \"\")\n",
    "        ax.text(xpos, -0.05, f'{xpos}', horizontalalignment='center', verticalalignment='center', \n",
    "                 color='white', fontsize=8, fontweight='bold', \n",
    "                 bbox=dict(facecolor=cmap(strength), edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    ax.set_ylim(-0.15, 1)\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_xlabel('Marker Position')\n",
    "    ax.set_title('Proportion of Alleles 0 and 1 at Each Marker' + (' (Sorted by Allele 0)' if sort_by_allele_0 else ''))\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def create_frame(farm, episode):\n",
    "    temp_dir = farm.temp_dir\n",
    "    fig = plt.figure(figsize=(10, 15))  # Adjust the figure size\n",
    "\n",
    "    gs = gridspec.GridSpec(3, 1, figure=fig)\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    farm.view_policy(ax1, episode)\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    plot_population_heatmap(ax2, self.current_population, self.marker_strength)\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    plot_allele_frequencies(ax3, self.current_population, self.marker_strength)\n",
    "\n",
    "    # Save the figure as a png in the temporary directory\n",
    "    filename = os.path.join(temp_dir.name, f'frame_{episode}.png')\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # Close the plot\n",
    "\n",
    "    return filename  # Return the filename for future use\n",
    "def select_parents(policy):\n",
    "    # Calculate the number of top elements to select.\n",
    "    k = policy.shape[1] // 2\n",
    "    # If the tensor has an odd number of elements, add one to 'k' to get the upper half.\n",
    "    if policy.shape[1] % 2 != 0:\n",
    "        k += 1\n",
    "    values, indices = tf.math.top_k(policy, k)\n",
    "    return values,indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZATIONS\n",
    "\n",
    "\n",
    "\n",
    "#average fitness for each episode\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def truncate_cycle(x):\n",
    "    nInd = x.current_population.shape[0]\n",
    "    top5 = x.simulator.select(x.current_population,k=nInd // 2)\n",
    "    new_pop = x.simulator.random_crosses(top5,n_crosses=nInd)\n",
    "    x.history.append(x.simulator.GEBV(new_pop))\n",
    "    x.current_population = new_pop\n",
    "\n",
    "\n",
    "def baseline_plot():\n",
    "    total_cycles = 20\n",
    "    trunk_farm = farm\n",
    "    for i in range(total_cycles):\n",
    "        truncate_cycle(trunk_farm)\n",
    "\n",
    "    data = [x.to_numpy().flatten() for x in trunk_farm.history]\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  # Optional: You can set the figure size\n",
    "    sns.boxplot(data=df)\n",
    "\n",
    "    plt.title('Baseline Heuristic')  # Add title\n",
    "    plt.xlabel('Episode Number')  # Add x-axis label\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_initial_population_policy_tracker_updated(dataset, indices, true_values, ax=None):\n",
    "    def top_50_percent_indices(array):\n",
    "        \"\"\"Helper function to find the top 50% indices of an array.\"\"\"\n",
    "        threshold = np.percentile(array, 50)\n",
    "        return np.where(array > threshold)\n",
    "\n",
    "    # Plotting\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))  # Create a new figure and axes if none is provided\n",
    "\n",
    "    # Preparing the data for imshow - adding the 'true_values' as the first column\n",
    "    data_for_plotting = np.column_stack([true_values.squeeze()] + [d.squeeze() for d in dataset])\n",
    "\n",
    "    # Displaying the arrays as columns with appropriate coloring\n",
    "    ax.imshow(data_for_plotting, aspect='auto', cmap=plt.cm.viridis)\n",
    "\n",
    "    # Adding red rectangles for top 50% values in each array, including 'true_values'\n",
    "    all_data = [true_values] + dataset\n",
    "    for i, array in enumerate(all_data):\n",
    "        top_indices = top_50_percent_indices(array.squeeze())\n",
    "        for index in top_indices[0]:\n",
    "            rect = plt.Rectangle((i-0.5, index-0.5), 1, 1, edgecolor='red', facecolor='none', lw=3)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    # Setting the axis labels and title\n",
    "    ax.set_xlabel(\"Episode Number\")\n",
    "    ax.set_ylabel(\"Individual ID\")\n",
    "\n",
    "    # Setting x-axis tick labels to include 'Truth' for the first column and sampled indices for the rest\n",
    "    tick_labels = ['Truncation'] + [f\"{idx+1}\" for idx in indices]\n",
    "    plt.xticks(range(len(all_data)), tick_labels)\n",
    "\n",
    "    plt.yticks(range(len(true_values.squeeze())), range(len(true_values.squeeze())))\n",
    "\n",
    "    # Adding grid lines\n",
    "    ax.grid(True, which='both', axis='both', linestyle='-', color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    ax.set_title(\"Initial Population Policy Tracker\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_dataset_by_percentile(dataset, percentile):\n",
    "    \"\"\"\n",
    "    Samples a dataset based on a given percentile and returns the sampled data along with their original indices.\n",
    "\n",
    "    :param dataset: List or array-like structure containing the dataset.\n",
    "    :param percentile: The percentile step to use for sampling (e.g., 10 for 10th percentile steps).\n",
    "\n",
    "    :return: A tuple containing two lists - the sampled dataset and their corresponding indices.\n",
    "    \"\"\"\n",
    "    if not 0 < percentile <= 100:\n",
    "        raise ValueError(\"Percentile must be between 0 and 100\")\n",
    "\n",
    "    num_elements = len(dataset)\n",
    "    step = int(num_elements * (percentile / 100))\n",
    "    \n",
    "    # Handle the case where step size is 0 due to a very small dataset\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "\n",
    "    # Sampling indices\n",
    "    sampled_indices = range(0, num_elements, step)\n",
    "\n",
    "    # Sampling the dataset\n",
    "    sampled_dataset = [dataset[i] for i in sampled_indices]\n",
    "\n",
    "    return sampled_dataset, list(sampled_indices)\n",
    "\n",
    "def baseline_plot(ax=None):\n",
    "    total_cycles = 20\n",
    "    trunk_farm = farm\n",
    "    for i in range(total_cycles):\n",
    "        truncate_cycle(trunk_farm)\n",
    "\n",
    "    data = [x.to_numpy().flatten() for x in trunk_farm.history]\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))  # Create a new figure and axes if none is provided\n",
    "\n",
    "    sns.boxplot(data=df, ax=ax)\n",
    "\n",
    "    ax.set_title('Baseline Heuristic')  # Add title\n",
    "    ax.set_xlabel('Episode Number')  # Add x-axis label\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "def fitness_plot(ax=None):\n",
    "    mean_score_list = [x.mean() for x in farm.fitness_history]\n",
    "    mean_score_series = pd.Series(mean_score_list)\n",
    "\n",
    "    # Calculate the rolling average\n",
    "    rolling_mean = mean_score_series.rolling(window=100).mean()\n",
    "\n",
    "    # Create the plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))  # Create a new figure and axes if none is provided\n",
    "\n",
    "    ax.plot(mean_score_series, label='Original')\n",
    "    ax.plot(rolling_mean, 'r-', label='Rolling Average')\n",
    "    ax.set_title(\"population_fitness (higher is better)\")\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Example usage:\n",
    "# sampled_data, sampled_indices  = sample_dataset_by_percentile(farm.fitness_history, 10)\n",
    "# plot_initial_population_policy_tracker_updated(sampled_data, sampled_indices, farm.simulator.GEBV(farm.initial_population) )\n",
    "\n",
    "# baseline_plot()\n",
    "\n",
    "# fitness_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "\n",
    "def create_critic(n, m, d, population_dummy, scores_dummy, output_dummy):\n",
    "    # Create an additional input for the scores and actor's output\n",
    "    score_input = keras.layers.Input(shape=(n,))\n",
    "    actor_output_input = keras.layers.Input(shape=output_dummy.shape[1:])\n",
    "\n",
    "    # Define the critic model\n",
    "    critic_input = keras.layers.Input(shape=(n, m, d))\n",
    "\n",
    "    x1 = Flatten()(critic_input)\n",
    "    x2 = Dense(64, activation='relu')(score_input)  # Dense layer for the scores\n",
    "    x3 = Flatten()(actor_output_input)  # Flatten the actor's output\n",
    "    x = keras.layers.Concatenate()([x1, x2, x3])  # Concatenate the flattened critic input, score input, and actor's output\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='linear')(x)  # Output layer with single linear unit\n",
    "\n",
    "    critic_model = keras.models.Model([critic_input, score_input, actor_output_input], x)\n",
    "    critic_model.compile(optimizer='adam', loss='mean_squared_error')  # Use MSE loss for value prediction\n",
    "\n",
    "    return critic_model\n",
    "\n",
    "def create_actor(n, m, d, total_parents, population_dummy, scores_dummy):\n",
    "    # Create an additional input for the scores\n",
    "    score_input = keras.layers.Input(shape=(n,))\n",
    "\n",
    "    # Define the actor model\n",
    "    actor_input = keras.layers.Input(shape=(n, m, d))\n",
    "\n",
    "    x1 = Flatten()(actor_input)\n",
    "    x2 = Dense(64, activation='relu')(score_input)  # Dense layer for the scores\n",
    "    x = keras.layers.Concatenate()([x1, x2])  # Concatenate the flattened actor input and the score input\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(n, activation='linear')(x)  # Output layer with n linear units\n",
    "\n",
    "    actor_model = keras.models.Model([actor_input, score_input], x)\n",
    "    actor_model.compile(optimizer='adam', loss='mean_squared_error')  # Use MSE loss for value prediction\n",
    "\n",
    "    return actor_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#dummy functions to  generate fake data to develop the training pipeline\n",
    "def pop_gen(b, n, m, d):\n",
    "    return np.random.randint(2, size=(b, n, m, d))\n",
    "def reward_gen():\n",
    "    return np.random.rand\n",
    "def scores_gen(n):\n",
    "    return np.random.rand(1, n)\n",
    "\n",
    "n = int(nInd[0])\n",
    "m = int(nMarkers)\n",
    "d = 2\n",
    "total_parents = n*2\n",
    "population_dummy = pop_gen(1, n, m, d)  # Extra dimension for batch size\n",
    "scores_dummy =  scores_gen(n) # Extra dimension for batch size\n",
    "#init actor and critic models\n",
    "actor_model = create_actor(n,m,d,total_parents, population_dummy, scores_dummy)\n",
    "# Feed the dummy data through the network to get an example for creating critic model\n",
    "actor_output = actor_model([population_dummy, scores_dummy])\n",
    "critic_model = create_critic(n,m,d, population_dummy, scores_dummy,actor_output)\n",
    "\n",
    "\n",
    "#HOW TO TAKE ACTION\n",
    "policy = actor_output # find the policy\n",
    "parent_values, parent_indices = select_parents(policy) #select parents\n",
    "selected_parents = population_dummy[0][parent_indices.numpy()] #grab parents from our current population\n",
    "#HOW TO CALCULATE REWARD\n",
    "past_fitness = scores_gen(n)\n",
    "new_fitness = scores_gen(n)\n",
    "reward = new_fitness-past_fitness\n",
    "\n",
    "# update the actor\n",
    "with tf.GradientTape() as tape:\n",
    "    new_policy = actor_model([population_dummy, scores_dummy], training=True)  # compute new policy with actor\n",
    "    actor_loss = -tf.reduce_mean(critic_model([population_dummy, scores_dummy, new_policy]))  # compute actor loss\n",
    "# Get the gradients\n",
    "actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "# Update the weights\n",
    "actor_model.optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "\n",
    "# update the critic\n",
    "with tf.GradientTape() as tape:\n",
    "    critic_value = critic_model([population_dummy, scores_dummy, actor_output], training=True)  # compute critic value\n",
    "    critic_loss = tf.keras.losses.MSE(reward, critic_value)  # compute critic loss\n",
    "# Get the gradients\n",
    "critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "# Update the weights\n",
    "critic_model.optimizer.apply_gradients(zip(critic_grad, critic_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.engine.functional.Functional"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(critic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape haplo (10, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "class BreedingProgram:\n",
    "    \"\"\"\n",
    "    Represents a breeding program with a PPO agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial_population, genetic_map, population_size, marker_count, chromosome_number, max_generation, heritability):\n",
    "        \"\"\"\n",
    "        Initializes the breeding program.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the basic attributes\n",
    "        self.population_size = population_size\n",
    "        self.marker_count = marker_count\n",
    "        self.initial_population = initial_population\n",
    "        self.genetic_map = genetic_map\n",
    "        self.max_generation = max_generation\n",
    "        self.marker_strength = np.array(self.genetic_map['Yield'])\n",
    "\n",
    "        # Initialize the simulator\n",
    "        self.simulator = Simulator(genetic_map=self.genetic_map, h2=heritability)\n",
    "        self.simulator.load_population('mypop.npy')\n",
    "        self.initial_scores = self.simulator.GEBV(self.initial_population)\n",
    "\n",
    "        #tempdir\n",
    "        self.temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "#actor_model = create_actor(n,m,d,total_parents, population_dummy, scores_dummy)\n",
    "\n",
    "        # Initialize the current generation and history\n",
    "        self.current_generation = 0\n",
    "        self.history = []\n",
    "\n",
    "        # Initialize the Actor and Critic models\n",
    "        #actor_model = create_actor(n,m,d,total_parents, population_dummy, scores_dummy)\n",
    "\n",
    "        self.actor = create_actor(n=self.population_size,\n",
    "                                  m=self.marker_count,\n",
    "                                  d=2,\n",
    "                                  total_parents = self.population_size,\n",
    "                                  population_dummy = self.initial_population, \n",
    "                                  scores_dummy=self.simulator.phenotype(self.initial_population)\n",
    "                                  )\n",
    "        population_dummy = np.random.rand(1, self.population_size,self.marker_count,2)  # Extra dimension for batch size\n",
    "        scores_dummy = np.random.rand(1, self.population_size)  # Extra dimension for batch size\n",
    "        output_dummy = self.actor([population_dummy, scores_dummy])\n",
    "        self.critic = create_critic(n=self.population_size,\n",
    "                                  m=self.marker_count,\n",
    "                                  d=2,\n",
    "                                  population_dummy = self.initial_population, \n",
    "                                  scores_dummy=self.simulator.phenotype(self.initial_population),\n",
    "                                  output_dummy = output_dummy)\n",
    "        \n",
    "\n",
    "        # self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "        # self.critic_optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "        # self.critic_history = []\n",
    "        # self.actor_history = []\n",
    "        # self.reward_history = []\n",
    "        # self.fitness_history = []\n",
    "        # self.snapshot_history = []\n",
    "\n",
    "                # Start the breeding program\n",
    "        self._start_breeding_program()\n",
    "        \n",
    "    def _start_breeding_program(self):\n",
    "        \"\"\"\n",
    "        Starts the breeding program.\n",
    "        \"\"\"\n",
    "        self.current_population = self.initial_population\n",
    "        self.current_scores = self.simulator.GEBV(self.initial_population)\n",
    "        self.history.append(self.current_scores)\n",
    "        self.agent_history = []\n",
    "        # self.snapshot_history.append(self.actor([self.initial_population.reshape(1, *self.initial_population.shape), self.initial_scores.to_numpy().transpose()], training=True).numpy())\n",
    " \n",
    "    def run_training(self, num_episodes, num_cycles):\n",
    "                \n",
    "        #set LR and Optimizer for actor/critic for each training run\n",
    "        self.actor_optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        self.critic_optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "        for episode in tqdm(range(num_episodes)):\n",
    "            if episode % 2 == 0:\n",
    "                print(psutil.Process().memory_info().rss / (1024 ** 2))\n",
    "            self.run_episode(num_cycles)\n",
    "\n",
    "    def run_episode(self,num_cycles):\n",
    "        for i in range(num_cycles):\n",
    "            # Check available memory\n",
    "            mem_info = psutil.virtual_memory()\n",
    "            available_mem = mem_info.available / (1024 ** 2)  # Convert bytes to MB\n",
    "            if available_mem < 200:  # If available memory is less than 200MB\n",
    "                print(\"Low memory! Available memory is less than 200MB. Stopping program.\")\n",
    "                break\n",
    "            else:\n",
    "                self.run_cycle(i)\n",
    "                # self.fitness_history.append(self.last_fitness)\n",
    "        print(f'''\n",
    "            init pop mean fitness {self.simulator.GEBV(self.initial_population).mean()}\n",
    "            final episode mean fitness {self.simulator.GEBV(self.current_population).mean()}\n",
    "\n",
    "              ''')\n",
    "        self.current_population = self.initial_population\n",
    "\n",
    "    def run_cycle(self, i):\n",
    "        # Prepare inputs for actor model\n",
    "        current_pop = torch.from_numpy(device_get(self.current_population.reshape(1, *self.current_population.shape)))\n",
    "        current_scores = self.simulator.GEBV(current_pop[0])\n",
    "        current_scores = torch.from_numpy(current_scores.to_numpy().transpose())\n",
    "\n",
    "        # Get policy and select parents\n",
    "        policy = self.actor([current_pop, current_scores])\n",
    "        parent_values, parent_indices = select_parents(policy)\n",
    "        selected_parents = self.current_population[parent_indices.numpy()] #switch to current_pop\n",
    "\n",
    "        # Calculate reward\n",
    "        past_fitness = self.simulator.GEBV(self.current_population).mean()\n",
    "        new_pop = self.simulator.random_crosses(selected_parents[0], n_crosses = current_pop[0].shape[0])\n",
    "        new_fitness = self.simulator.GEBV(new_pop)\n",
    "        reward = new_fitness.mean() - past_fitness\n",
    "\n",
    "        # Update actor with gradient descent, adding gradient clipping\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        new_policy = self.actor([current_pop, current_scores])\n",
    "        actor_loss = -torch.mean(self.critic([current_pop, current_scores, new_policy]))\n",
    "        actor_loss.backward()\n",
    "        actor_grad = [p.grad for p in self.actor.parameters()]\n",
    "        actor_grad = [(torch.clamp(grad, -1.0, 1.0)) for grad in actor_grad]  # Gradient clipping\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "    def agent_select(self,population):\n",
    "        \"\"\"\n",
    "        used to test the existing agent given a population\n",
    "        \"\"\"\n",
    "        # Prepare inputs for actor model\n",
    "        current_pop = device_get(population.reshape(1, *population.shape))\n",
    "        current_scores = self.simulator.GEBV(current_pop[0])\n",
    "        current_scores = current_scores.to_numpy().transpose()\n",
    "\n",
    "        # Get policy and select parents\n",
    "        policy = self.actor([current_pop, current_scores])\n",
    "\n",
    "        return policy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "initial_population =  reshape_pop(maizeHaplo) \n",
    "genetic_map = return_genetic_map_df(markerEffects, nChr, geneticMap)\n",
    "genetic_map['Yield'] = simplify_geneticmap(list(genetic_map['Yield']),4)\n",
    "reshapeHaplo = reshape_pop(maizeHaplo)\n",
    "np.save('mypop', reshapeHaplo)\n",
    "print(f'reshape haplo {reshapeHaplo.shape}')\n",
    "population_size = int(nInd)\n",
    "marker_count = int((segSites * nChr))\n",
    "chromosome_number = int(nChr)\n",
    "max_generation = 10\n",
    "heritability = .95\n",
    "mean_score_list=[]\n",
    "critic_loss_list=[]\n",
    "\n",
    "farm  = BreedingProgram(initial_population, genetic_map, population_size, marker_count, chromosome_number, max_generation, heritability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106.98046875\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dtype torch.int32 not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/jax/_src/api_util.py:563\u001b[0m, in \u001b[0;36mshaped_abstractify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 563\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_shaped_abstractify_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'torch.Tensor'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/jax/_src/dtypes.py:146\u001b[0m, in \u001b[0;36m_canonicalize_dtype\u001b[0;34m(x64_enabled, allow_opaque_dtype, dtype)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m   dtype_ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.int32' as a data type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfarm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 84\u001b[0m, in \u001b[0;36mBreedingProgram.run_training\u001b[0;34m(self, num_episodes, num_cycles)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(psutil\u001b[38;5;241m.\u001b[39mProcess()\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_cycles\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 95\u001b[0m, in \u001b[0;36mBreedingProgram.run_episode\u001b[0;34m(self, num_cycles)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# self.fitness_history.append(self.last_fitness)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124m    init pop mean fitness \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39mGEBV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_population)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124m    final episode mean fitness \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulator\u001b[38;5;241m.\u001b[39mGEBV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_population)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 107\u001b[0m, in \u001b[0;36mBreedingProgram.run_cycle\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_cycle\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Prepare inputs for actor model\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     current_pop \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(device_get(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_population\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_population\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[0;32m--> 107\u001b[0m     current_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEBV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     current_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(current_scores\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mtranspose())\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# Get policy and select parents\u001b[39;00m\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/chromax/simulator.py:503\u001b[0m, in \u001b[0;36mSimulator.GEBV\u001b[0;34m(self, population, raw_array)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGEBV\u001b[39m(\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    472\u001b[0m     population: Population[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    474\u001b[0m     raw_array: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    475\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m    476\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the Genomic Estimated Breeding Values using the\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m    marker effects from the genetic_map.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m        dtype: float32\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m     GEBV \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEBV_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_array:\n\u001b[1;32m    505\u001b[0m         GEBV \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(GEBV, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrait_names)\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/chromax/trait_model.py:31\u001b[0m, in \u001b[0;36mTraitModel.__call__\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     population: Population[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn traits\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarker_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/jax/_src/dtypes.py:148\u001b[0m, in \u001b[0;36m_canonicalize_dtype\u001b[0;34m(x64_enabled, allow_opaque_dtype, dtype)\u001b[0m\n\u001b[1;32m    146\u001b[0m   dtype_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 148\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x64_enabled:\n\u001b[1;32m    151\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dtype_\n",
      "\u001b[0;31mTypeError\u001b[0m: dtype torch.int32 not understood"
     ]
    }
   ],
   "source": [
    "import psutil, gc\n",
    "farm.run_training(500,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm.last_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm.simulator.GEBV(farm.initial_population).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm.simulator.GEBV(farm.initial_population).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "\n",
    "window_size = 2\n",
    "\n",
    "\n",
    "# Create a 4x3 grid\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "gs = gridspec.GridSpec(4, 3)\n",
    "\n",
    "# Prepare pandas Series for rolling averages\n",
    "critic_history = pd.Series(farm.critic_history)\n",
    "actor_history = pd.Series(farm.actor_history)\n",
    "reward_history = pd.Series(farm.reward_history)\n",
    "\n",
    "# Calculate rolling averages\n",
    "critic_history_avg = critic_history.rolling(window=window_size).mean()\n",
    "actor_history_avg = actor_history.rolling(window=window_size).mean()\n",
    "reward_history_avg = reward_history.rolling(window=window_size).mean()\n",
    "\n",
    "# Add existing plots on the top row\n",
    "ax1 = plt.subplot(gs[0, 0])\n",
    "ax1.plot(critic_history, label='Original')\n",
    "ax1.plot(critic_history_avg, 'r-', label='Rolling Average')\n",
    "ax1.set_title('Critic Loss History - per step')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.tick_params(labelbottom=False)  # Hide x-axis label\n",
    "\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax2.plot(actor_history, label='Original')\n",
    "ax2.plot(actor_history_avg, 'r-', label='Rolling Average')\n",
    "ax2.set_title('Actor Loss History - per step')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.tick_params(labelbottom=False)  # Hide x-axis label\n",
    "\n",
    "ax3 = plt.subplot(gs[0, 2])\n",
    "ax3.plot(reward_history, label='Original')\n",
    "ax3.plot(reward_history_avg, 'r-', label='Rolling Average')\n",
    "ax3.set_title('Reward History - per step')\n",
    "ax3.legend(loc='upper left')\n",
    "ax3.tick_params(labelbottom=False)  # Hide x-axis label\n",
    "\n",
    "# Add fitness_plot on the second row\n",
    "ax4 = plt.subplot(gs[1, :])\n",
    "fitness_plot(ax4)\n",
    "\n",
    "# Add plot_initial_population_policy_tracker_updated on the third row\n",
    "ax5 = plt.subplot(gs[2, :])\n",
    "sampled_data, sampled_indices = sample_dataset_by_percentile(farm.fitness_history, 10)\n",
    "plot_initial_population_policy_tracker_updated(sampled_data, sampled_indices, farm.simulator.GEBV(farm.initial_population), ax5)\n",
    "\n",
    "# Add baseline_plot on the fourth row\n",
    "ax6 = plt.subplot(gs[3, :])\n",
    "baseline_plot(ax6)\n",
    "\n",
    "# Adjust the space between rows\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Display the figure with the subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
