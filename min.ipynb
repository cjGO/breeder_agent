{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from chromax import Simulator\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import choice\n",
    "from typing import Dict, Any, List\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "\n",
    "def init_program():\n",
    "    number_individuals = 50  # Replace with your actual number of individuals\n",
    "    number_markers = 100     # Replace with your actual number of markers\n",
    "    ploidy = 2              # Replace with your actual ploidy level\n",
    "    batch_size = 3\n",
    "    initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "    #printshape('first pop shape' , initial_population)\n",
    "    genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "    marker_strength = np.array(genetic_map_df['Yield'])\n",
    "    fraction_selection = 10\n",
    "\n",
    "    #score init pop\n",
    "    initial_score = np.array([calculate_scores(x,marker_strength) for x in initial_population])\n",
    "    #printshape('first score list shape' , initial_score)\n",
    "\n",
    "    #score2hist(initial_score)\n",
    "\n",
    "    return initial_population, initial_score, genetic_map_df, marker_strength\n",
    "\n",
    "def create_fake_geneticmap(number_markers:int):\n",
    "    \"\"\"The genetic map represents the rules of the game. It assigns the truth value to each marker.\n",
    "\n",
    "    :param number_markers: the total number of markers to include in this genetic map. must correspond to population shape\n",
    "    :type number_markers: int \n",
    "    \"\"\"\n",
    "    # 'chr' will always be '1A' for every marker\n",
    "    chr_array = ['1A'] * number_markers\n",
    "    \n",
    "    # 'yield': Create a marker_strength array with 1 float between -0.5 and +0.5 randomly\n",
    "    # yield_array = np.random.poisson(np.random.randint(1,10), size=number_markers)\n",
    "    poisson_values = np.random.poisson(np.random.randint(1, 10), size=number_markers)\n",
    "\n",
    "    # Scale the Poisson values to the range [0, 1]\n",
    "    scaled_poisson_values = poisson_values / np.max(poisson_values)\n",
    "\n",
    "    # Stretch and shift the values to the range [-1, 1]\n",
    "    yield_array = (scaled_poisson_values * 2) - 1\n",
    "    \n",
    "    # 'cM': create an array for number_markers length evenly sampled between 0 and 100\n",
    "    cM_array = np.linspace(0, 100, num=number_markers)\n",
    "    \n",
    "    # Create the DataFrame with the auto-generated data\n",
    "    df = pd.DataFrame({'CHR.PHYS': chr_array, 'Yield': yield_array, 'cM': cM_array*.01})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_fake_population(total_pops:int, number_individuals:int, number_markers:int, ploidy:int):\n",
    "    \"\"\"\n",
    "        Creates a batch of populations. A populations is a group of individuals. An individual is composed of markers. Markers are 0 or 1\n",
    "\n",
    "        Returns : binary array shape (total_pops, number_individuals, number_markers, ploidy)\n",
    "    \"\"\"\n",
    "    # List of generation methods\n",
    "    generation_methods = [\n",
    "        lambda: np.random.randint(2, size=(number_individuals, number_markers, ploidy)),\n",
    "        lambda: np.random.choice([0, 1], size=(number_individuals, number_markers, ploidy))\n",
    "    ]\n",
    "    \n",
    "    populations = []\n",
    "    for _ in range(total_pops):\n",
    "        # Randomly select a generation method and generate the population\n",
    "        gen_method = choice(generation_methods)\n",
    "        population = gen_method()\n",
    "        populations.append(population)\n",
    "        \n",
    "    # Combine all populations into a single numpy array\n",
    "    combined_population = np.array(populations)\n",
    "\n",
    "    return combined_population\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_scores(population, marker_strength):\n",
    "    \"\"\"\n",
    "    Calculates the additive score by matrix multipling the population (n,m) with the marker strengths (m,)\n",
    "    \"\"\"\n",
    "    # Perform a dot product between the dosages and marker strength arrays\n",
    "    dosages = np.sum(population,axis=2)\n",
    "    scores = np.dot(dosages, marker_strength)\n",
    "    return scores\n",
    "\n",
    "def panmixia(selected_parents, total_offspring):\n",
    "    \"\"\" Handles the random crossing for us ; heuristic!\n",
    "\n",
    "    selected_parents ( n , m , d )\n",
    "    \n",
    "    \"\"\"\n",
    "    n, m, d = selected_parents.shape\n",
    "    offspring_target = total_offspring\n",
    "    offspring_list = []\n",
    "\n",
    "    while len(offspring_list) < offspring_target:\n",
    "        # Randomly pick two parents without replacement\n",
    "        parents_indices = np.random.choice(n, size=2, replace=False)\n",
    "        parent1, parent2 = selected_parents[parents_indices]\n",
    "\n",
    "        # Simulate random recombination for each marker\n",
    "        offspring = np.zeros((m, d), dtype=parent1.dtype)\n",
    "        for i in range(m):\n",
    "            # Randomly choose one allele from each parent for each marker\n",
    "            for j in range(d):\n",
    "                parent_allele = np.random.choice([parent1[i, j], parent2[i, j]])\n",
    "                offspring[i, j] = parent_allele\n",
    "\n",
    "        # Add the new offspring to the offspring list\n",
    "        offspring_list.append(offspring)\n",
    "\n",
    "    # Convert offspring list to a numpy array with shape (offspring_target, m, d)\n",
    "    offspring_array = np.array(offspring_list)\n",
    "    return offspring_array\n",
    "\n",
    "\n",
    "def scores2parents(scores,K):\n",
    "    \"\"\"\n",
    "    hint: use output from calculate_scores\n",
    "    \"\"\"\n",
    "    # Specify the number of top values you want (K)\n",
    "    K = 5\n",
    "\n",
    "    # Get the indices that would sort the array\n",
    "    sorted_indices = np.argsort(scores)\n",
    "\n",
    "    # Take the last K indices of the sorted indices array\n",
    "    top_k_indices = sorted_indices[-K:]\n",
    "\n",
    "    # Since argsort returns indices in ascending order, reverse to get the top values\n",
    "    top_k_indices = top_k_indices[::-1]\n",
    "\n",
    "    print(\"Indices of top K values:\", top_k_indices)\n",
    "    print(\"Top K values:\", scores[top_k_indices])\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "def select_parents(policy, total_parents):\n",
    "    \"\"\"\n",
    "        input: Policy from actor ( score or metric value for each individual )\n",
    "        returns : index of parents to be included in random_crosses for next step of breeding program\n",
    "    \"\"\"\n",
    "    # Use numpy's argsort function to get the indices of the top 'total_parents' values\n",
    "    indices = np.argsort(policy)[-total_parents:]\n",
    "    values = policy[indices]\n",
    "    return values,indices\n",
    "\n",
    "def printshape(message , arr):\n",
    "    print(f'{message} {arr.shape}')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def score2hist(score, title='population score distribution'):\n",
    "    #e.g. (3,50) array\n",
    "\n",
    "    # Assuming 'data' is your (3,50) array\n",
    "    data = score\n",
    "\n",
    "    # Plot KDE for each row in the data\n",
    "    for i in range(data.shape[0]):\n",
    "        kde = gaussian_kde(data[i])\n",
    "        dist_space = np.linspace(min(data[i]), max(data[i]), 100)\n",
    "        plt.plot(dist_space, kde(dist_space), label=f'Distribution {i+1}')\n",
    "\n",
    "    # Adding labels and legend\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "number_individuals = 50  # Replace with your actual number of individuals\n",
    "number_markers = 100     # Replace with your actual number of markers\n",
    "ploidy = 2              # Replace with your actual ploidy level\n",
    "batch_size = 3\n",
    "initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "marker_strength = np.array(genetic_map_df['Yield'])\n",
    "fraction_selection = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def init_program():\n",
    "    number_individuals = 50  # Replace with your actual number of individuals\n",
    "    number_markers = 100     # Replace with your actual number of markers\n",
    "    ploidy = 2               # Replace with your actual ploidy level\n",
    "    batch_size = 3\n",
    "    initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "    genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "    marker_strength = np.array(genetic_map_df['Yield'])\n",
    "    fraction_selection = 10\n",
    "\n",
    "    # Convert marker_strength to a PyTorch tensor\n",
    "    marker_strength_tensor = torch.tensor(marker_strength, dtype=torch.float32)\n",
    "\n",
    "    # Score the initial population\n",
    "    initial_score = np.array([calculate_scores(torch.tensor(x, dtype=torch.float32), marker_strength_tensor).numpy() for x in initial_population])\n",
    "\n",
    "    return initial_population, initial_score, genetic_map_df, marker_strength\n",
    "\n",
    "# Make sure the calculate_scores function is defined correctly as shown in the previous response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #random selection baseline\n",
    "\n",
    "# initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "# current_population = initial_population\n",
    "# current_score = initial_score\n",
    "\n",
    "# for _ in range(5):\n",
    "#     #select random half of individuals in each pop\n",
    "#     selected_parents = current_population[:,:25,:,:]\n",
    "#     selected_parents_score = np.array([calculate_scores(x, marker_strength) for x in selected_parents])\n",
    "#     new_pop = np.array([panmixia(x, total_offspring=initial_population.shape[1]) for x in selected_parents])\n",
    "#     new_score = np.array([calculate_scores(x, marker_strength) for x in new_pop])\n",
    "    \n",
    "#     current_population = new_pop\n",
    "#     current_score = new_score\n",
    "#     score2hist(selected_parents_score, title='selected parents scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #truncation selection baseline\n",
    "\n",
    "# initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "# current_population = initial_population\n",
    "# current_score = initial_score\n",
    "\n",
    "# frames = []\n",
    "# for _ in range(5):\n",
    "#     #select top half of individuals in each pop\n",
    "#     truncation = [select_parents(x,int(initial_population.shape[1]/2)) for x in current_score]\n",
    "#     parent_index = [x[1] for x in truncation]\n",
    "#     parent_metric = [x[0] for x in truncation]\n",
    "#     parent_pop = np.array([x[y] for x,y in zip(current_population, parent_index)])    \n",
    "#     new_pop = np.array([panmixia(x, total_offspring=initial_population.shape[1]) for x in parent_pop])\n",
    "#     new_score = np.array([calculate_scores(x, marker_strength) for x in new_pop])\n",
    "    \n",
    "#     current_population = new_pop\n",
    "#     current_score = new_score\n",
    "#     score2hist(current_score)\n",
    "#     frames.append(current_score)\n",
    "\n",
    "# frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_normal_\n",
    "\n",
    "class ActorModel(nn.Module):\n",
    "    def __init__(self, num_individual, num_markers, ploidy, use_skip_connection=False):\n",
    "        super(ActorModel, self).__init__()\n",
    "        \n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        # Flatten layers for population and phenotype inputs\n",
    "        self.flatten_population = nn.Flatten()\n",
    "        self.flatten_phenotype = nn.Flatten()\n",
    "        \n",
    "        # Combined input size calculation\n",
    "        combined_input_size = num_individual * num_markers * ploidy + num_individual\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden1 = nn.Linear(combined_input_size, 64)\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.output = nn.Linear(64, num_individual)\n",
    "        \n",
    "        # Define the transformation layer for skip connection\n",
    "        if use_skip_connection:\n",
    "            self.phenotype_transform = nn.Linear(num_individual, 64)\n",
    "        \n",
    "        # Initialize weights using He initialization\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, population_input, phenotype_input):\n",
    "        # Flatten inputs\n",
    "        flat_population = self.flatten_population(population_input)\n",
    "        flat_phenotype = self.flatten_phenotype(phenotype_input)\n",
    "        \n",
    "        # Combine inputs\n",
    "        combined = torch.cat([flat_population, flat_phenotype], dim=1)\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        hidden1 = F.relu(self.hidden1(combined))\n",
    "        hidden2 = F.relu(self.hidden2(hidden1))\n",
    "        \n",
    "        # Check if skip connection is to be used\n",
    "        if self.use_skip_connection:\n",
    "            phenotype_transformed = F.relu(self.phenotype_transform(flat_phenotype))\n",
    "            skip_connection = hidden2 + phenotype_transformed\n",
    "            output = F.softmax(self.output(skip_connection), dim=1)\n",
    "        else:\n",
    "            output = F.softmax(self.output(hidden2), dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "def calculate_scores(offspring, marker_tensor):\n",
    "    # Sum the contributions from both sets of chromosomes (ploidy)\n",
    "    summed_offspring = offspring.sum(dim=-1)  # This will sum across the ploidy dimension\n",
    "    \n",
    "    # Perform the dot product between the marker_tensor and the summed_offspring\n",
    "    # We need to unsqueeze the marker_tensor to perform batch matrix multiplication\n",
    "    marker_tensor_unsqueezed = marker_tensor.unsqueeze(0).unsqueeze(-1)\n",
    "    \n",
    "    # Perform batch matrix multiplication\n",
    "    scores = torch.matmul(summed_offspring, marker_tensor_unsqueezed)\n",
    "    \n",
    "    # Remove the last dimension and squeeze the result to get the final scores\n",
    "    scores = scores.squeeze(-1)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossover(parents, num_offspring_per_population):\n",
    "    num_populations, num_parents, num_markers, ploidy = parents.shape\n",
    "    offspring = torch.empty((num_populations, num_offspring_per_population, num_markers, ploidy), dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_populations):\n",
    "        for j in range(num_offspring_per_population):\n",
    "            # Randomly select two parents\n",
    "            parent_indices = torch.randperm(num_parents)[:2]\n",
    "            parent1 = parents[i, parent_indices[0]]\n",
    "            parent2 = parents[i, parent_indices[1]]\n",
    "\n",
    "            # Perform single crossover\n",
    "            crossover_point = torch.randint(low=1, high=num_markers, size=(1,)).item()\n",
    "            child1 = torch.cat((parent1[:crossover_point, :], parent2[crossover_point:, :]), dim=0)\n",
    "            child2 = torch.cat((parent2[:crossover_point, :], parent1[crossover_point:, :]), dim=0)\n",
    "\n",
    "            # Randomly select one of the two possible offspring\n",
    "            offspring[i, j] = child1 if torch.rand(1).item() < 0.5 else child2\n",
    "\n",
    "    return offspring\n",
    "\n",
    "# init the RL environment\n",
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "# init the Agent\n",
    "a = ActorModel(num_individual=initial_population.shape[1], num_markers = initial_population.shape[2], ploidy = initial_population.shape[3])\n",
    "\n",
    "# prep for torch\n",
    "population_tensor = torch.from_numpy(initial_population).float()\n",
    "score_tensor = torch.from_numpy(initial_score).float()\n",
    "score_tensor = score_tensor[:,0,:]\n",
    "marker_tensor = torch.from_numpy(marker_strength).float()\n",
    "\n",
    "# Perform the prediction\n",
    "with torch.no_grad():\n",
    "    prediction = a(population_tensor, score_tensor)\n",
    "\n",
    "# Sample 25 individuals from each population\n",
    "num_samples = 25\n",
    "samples = torch.multinomial(prediction, num_samples, replacement=True)\n",
    "\n",
    "# Create a tensor for the batch dimension which corresponds to each population\n",
    "batch_indices = torch.arange(population_tensor.size(0)).unsqueeze(1).expand_as(samples)\n",
    "\n",
    "# Use the batch_indices and samples to index into the initial_population tensor\n",
    "selected_parents = population_tensor[batch_indices, samples]\n",
    "\n",
    "# return: 50 offspring per population\n",
    "offspring_geno = crossover(selected_parents, 50)\n",
    "offspring_score = calculate_scores(offspring_geno, marker_tensor)\n",
    "\n",
    "# Calculate the mean of each array along axis 1\n",
    "offspring_score_mean = offspring_score.mean(dim=1, keepdim=True)\n",
    "score_tensor_mean = score_tensor.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Subtract the offspring_score mean from the score_tensor mean\n",
    "loss = offspring_score_mean - score_tensor_mean # WANT TO MAXIMIZE THIS !!! optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 147\u001b[0m\n\u001b[1;32m    145\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Backward pass to calculate the gradients (add this after zeroing the gradients)\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Update the weights (add this after calculating the gradients)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/torch/autograd/__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    236\u001b[0m     (inputs,)\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/breeder_agent/agent_env/lib/python3.8/site-packages/torch/autograd/__init__.py:117\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_normal_\n",
    "\n",
    "class ActorModel(nn.Module):\n",
    "    def __init__(self, num_individual, num_markers, ploidy, use_skip_connection=False):\n",
    "        super(ActorModel, self).__init__()\n",
    "        \n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        # Flatten layers for population and phenotype inputs\n",
    "        self.flatten_population = nn.Flatten()\n",
    "        self.flatten_phenotype = nn.Flatten()\n",
    "        \n",
    "        # Combined input size calculation\n",
    "        combined_input_size = num_individual * num_markers * ploidy + num_individual\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden1 = nn.Linear(combined_input_size, 64)\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.output = nn.Linear(64, num_individual)\n",
    "        \n",
    "        # Define the transformation layer for skip connection\n",
    "        if use_skip_connection:\n",
    "            self.phenotype_transform = nn.Linear(num_individual, 64)\n",
    "        \n",
    "        # Initialize weights using He initialization\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, population_input, phenotype_input):\n",
    "        # Flatten inputs\n",
    "        flat_population = self.flatten_population(population_input)\n",
    "        flat_phenotype = self.flatten_phenotype(phenotype_input)\n",
    "        \n",
    "        # Combine inputs\n",
    "        combined = torch.cat([flat_population, flat_phenotype], dim=1)\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        hidden1 = F.relu(self.hidden1(combined))\n",
    "        hidden2 = F.relu(self.hidden2(hidden1))\n",
    "        \n",
    "        # Check if skip connection is to be used\n",
    "        if self.use_skip_connection:\n",
    "            phenotype_transformed = F.relu(self.phenotype_transform(flat_phenotype))\n",
    "            skip_connection = hidden2 + phenotype_transformed\n",
    "            output = F.softmax(self.output(skip_connection), dim=1)\n",
    "        else:\n",
    "            output = F.softmax(self.output(hidden2), dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "def calculate_scores(offspring, marker_tensor):\n",
    "    # Sum the contributions from both sets of chromosomes (ploidy)\n",
    "    summed_offspring = offspring.sum(dim=-1)  # This will sum across the ploidy dimension\n",
    "    \n",
    "    # Perform the dot product between the marker_tensor and the summed_offspring\n",
    "    # We need to unsqueeze the marker_tensor to perform batch matrix multiplication\n",
    "    marker_tensor_unsqueezed = marker_tensor.unsqueeze(0).unsqueeze(-1)\n",
    "    \n",
    "    # Perform batch matrix multiplication\n",
    "    scores = torch.matmul(summed_offspring, marker_tensor_unsqueezed)\n",
    "    \n",
    "    # Remove the last dimension and squeeze the result to get the final scores\n",
    "    scores = scores.squeeze(-1)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossover(parents, num_offspring_per_population):\n",
    "    num_populations, num_parents, num_markers, ploidy = parents.shape\n",
    "    offspring = torch.empty((num_populations, num_offspring_per_population, num_markers, ploidy), dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_populations):\n",
    "        for j in range(num_offspring_per_population):\n",
    "            # Randomly select two parents\n",
    "            parent_indices = torch.randperm(num_parents)[:2]\n",
    "            parent1 = parents[i, parent_indices[0]]\n",
    "            parent2 = parents[i, parent_indices[1]]\n",
    "\n",
    "            # Perform single crossover\n",
    "            crossover_point = torch.randint(low=1, high=num_markers, size=(1,)).item()\n",
    "            child1 = torch.cat((parent1[:crossover_point, :], parent2[crossover_point:, :]), dim=0)\n",
    "            child2 = torch.cat((parent2[:crossover_point, :], parent1[crossover_point:, :]), dim=0)\n",
    "\n",
    "            # Randomly select one of the two possible offspring\n",
    "            offspring[i, j] = child1 if torch.rand(1).item() < 0.5 else child2\n",
    "\n",
    "    return offspring\n",
    "\n",
    "# init the RL environment\n",
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "# init the Agent\n",
    "a = ActorModel(num_individual=initial_population.shape[1], num_markers = initial_population.shape[2], ploidy = initial_population.shape[3])\n",
    "a.train()\n",
    "\n",
    "\n",
    "\n",
    "# prep for torch\n",
    "population_tensor = torch.from_numpy(initial_population).float()\n",
    "score_tensor = torch.from_numpy(initial_score).float()\n",
    "score_tensor = score_tensor[:,0,:]\n",
    "marker_tensor = torch.from_numpy(marker_strength).float()\n",
    "optimizer = optim.Adam(a.parameters(), lr=0.001)\n",
    "\n",
    "# Perform the prediction\n",
    "# with torch.no_grad():\n",
    "prediction = a(population_tensor, score_tensor)\n",
    "\n",
    "# Sample 25 individuals from each population\n",
    "num_samples = 25\n",
    "samples = torch.multinomial(prediction, num_samples, replacement=True)\n",
    "\n",
    "# Create a tensor for the batch dimension which corresponds to each population\n",
    "batch_indices = torch.arange(population_tensor.size(0)).unsqueeze(1).expand_as(samples)\n",
    "\n",
    "# Use the batch_indices and samples to index into the initial_population tensor\n",
    "selected_parents = population_tensor[batch_indices, samples]\n",
    "\n",
    "# return: 50 offspring per population\n",
    "offspring_geno = crossover(selected_parents, 50)\n",
    "offspring_score = calculate_scores(offspring_geno, marker_tensor)\n",
    "\n",
    "# Calculate the mean of each array along axis 1\n",
    "offspring_score_mean = offspring_score.mean(dim=1, keepdim=True)\n",
    "score_tensor_mean = score_tensor.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Subtract the offspring_score mean from the score_tensor mean\n",
    "loss = offspring_score_mean - score_tensor_mean\n",
    "# Convert the loss to a minimization problem (add this after calculating the loss)\n",
    "loss = -loss\n",
    "# Zero the gradients before running the backward pass (add this before calculating the gradients)\n",
    "optimizer.zero_grad()\n",
    "# Backward pass to calculate the gradients (add this after zeroing the gradients)\n",
    "loss.backward()\n",
    "\n",
    "# Update the weights (add this after calculating the gradients)\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the RL environment\n",
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "# init the Agent\n",
    "a = ActorModel(num_individual=initial_population.shape[1], num_markers = initial_population.shape[2], ploidy = initial_population.shape[3])\n",
    "a.train()\n",
    "\n",
    "# prep for torch\n",
    "population_tensor = torch.from_numpy(initial_population).float().requires_grad_(True)\n",
    "score_tensor = torch.from_numpy(initial_score).float().requires_grad_(True)\n",
    "score_tensor = score_tensor[:, 0, :].requires_grad_(True)\n",
    "marker_tensor = torch.from_numpy(marker_strength).float().requires_grad_(True)\n",
    "\n",
    "optimizer = optim.Adam(a.parameters(), lr=0.001)\n",
    "\n",
    "# Perform the prediction\n",
    "# with torch.no_grad():\n",
    "prediction = a(population_tensor, score_tensor)\n",
    "\n",
    "# Sample 25 individuals from each population\n",
    "num_samples = 25\n",
    "samples = torch.multinomial(prediction, num_samples, replacement=True)\n",
    "\n",
    "# Create a tensor for the batch dimension which corresponds to each population\n",
    "batch_indices = torch.arange(population_tensor.size(0)).unsqueeze(1).expand_as(samples)\n",
    "\n",
    "# Use the batch_indices and samples to index into the initial_population tensor\n",
    "selected_parents = population_tensor[batch_indices, samples]\n",
    "\n",
    "# return: 50 offspring per population\n",
    "offspring_geno = crossover(selected_parents, 50)\n",
    "offspring_score = calculate_scores(offspring_geno, marker_tensor)\n",
    "\n",
    "# Calculate the mean of each array along axis 1\n",
    "offspring_score_mean = offspring_score.mean(dim=1, keepdim=True)\n",
    "score_tensor_mean = score_tensor.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Subtract the offspring_score mean from the score_tensor mean and take the mean to get a scalar\n",
    "loss = (offspring_score_mean - score_tensor_mean).mean()\n",
    "# Convert the loss to a minimization problem (add this after calculating the loss)\n",
    "loss = -loss\n",
    "\n",
    "# Zero the gradients before running the backward pass (add this before calculating the gradients)\n",
    "optimizer.zero_grad()\n",
    "# Backward pass to calculate the gradients (add this after zeroing the gradients)\n",
    "loss.backward()\n",
    "\n",
    "# Update the weights (add this after calculating the gradients)\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
