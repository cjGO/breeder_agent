{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from chromax import Simulator\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import choice\n",
    "from typing import Dict, Any, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "\n",
    "def init_program():\n",
    "    number_individuals = 50  # Replace with your actual number of individuals\n",
    "    number_markers = 100     # Replace with your actual number of markers\n",
    "    ploidy = 2              # Replace with your actual ploidy level\n",
    "    batch_size = 3\n",
    "    initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "    #printshape('first pop shape' , initial_population)\n",
    "    genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "    marker_strength = np.array(genetic_map_df['Yield'])\n",
    "    fraction_selection = 10\n",
    "\n",
    "    #score init pop\n",
    "    initial_score = np.array([calculate_scores(x,marker_strength) for x in initial_population])\n",
    "    #printshape('first score list shape' , initial_score)\n",
    "\n",
    "    #score2hist(initial_score)\n",
    "\n",
    "    return initial_population, initial_score, genetic_map_df, marker_strength\n",
    "\n",
    "def create_fake_geneticmap(number_markers:int):\n",
    "    \"\"\"The genetic map represents the rules of the game. It assigns the truth value to each marker.\n",
    "\n",
    "    :param number_markers: the total number of markers to include in this genetic map. must correspond to population shape\n",
    "    :type number_markers: int \n",
    "    \"\"\"\n",
    "    # 'chr' will always be '1A' for every marker\n",
    "    chr_array = ['1A'] * number_markers\n",
    "    \n",
    "    # 'yield': Create a marker_strength array with 1 float between -0.5 and +0.5 randomly\n",
    "    # yield_array = np.random.poisson(np.random.randint(1,10), size=number_markers)\n",
    "    poisson_values = np.random.poisson(np.random.randint(1, 10), size=number_markers)\n",
    "\n",
    "    # Scale the Poisson values to the range [0, 1]\n",
    "    scaled_poisson_values = poisson_values / np.max(poisson_values)\n",
    "\n",
    "    # Stretch and shift the values to the range [-1, 1]\n",
    "    yield_array = (scaled_poisson_values * 2) - 1\n",
    "    \n",
    "    # 'cM': create an array for number_markers length evenly sampled between 0 and 100\n",
    "    cM_array = np.linspace(0, 100, num=number_markers)\n",
    "    \n",
    "    # Create the DataFrame with the auto-generated data\n",
    "    df = pd.DataFrame({'CHR.PHYS': chr_array, 'Yield': yield_array, 'cM': cM_array*.01})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_fake_population(total_pops:int, number_individuals:int, number_markers:int, ploidy:int):\n",
    "    \"\"\"\n",
    "        Creates a batch of populations. A populations is a group of individuals. An individual is composed of markers. Markers are 0 or 1\n",
    "\n",
    "        Returns : binary array shape (total_pops, number_individuals, number_markers, ploidy)\n",
    "    \"\"\"\n",
    "    # List of generation methods\n",
    "    generation_methods = [\n",
    "        lambda: np.random.randint(2, size=(number_individuals, number_markers, ploidy)),\n",
    "        lambda: np.random.choice([0, 1], size=(number_individuals, number_markers, ploidy))\n",
    "    ]\n",
    "    \n",
    "    populations = []\n",
    "    for _ in range(total_pops):\n",
    "        # Randomly select a generation method and generate the population\n",
    "        gen_method = choice(generation_methods)\n",
    "        population = gen_method()\n",
    "        populations.append(population)\n",
    "        \n",
    "    # Combine all populations into a single numpy array\n",
    "    combined_population = np.array(populations)\n",
    "\n",
    "    return combined_population\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_scores(population, marker_strength):\n",
    "    \"\"\"\n",
    "    Calculates the additive score by matrix multipling the population (n,m) with the marker strengths (m,)\n",
    "    \"\"\"\n",
    "    # Perform a dot product between the dosages and marker strength arrays\n",
    "    dosages = np.sum(population,axis=2)\n",
    "    scores = np.dot(dosages, marker_strength)\n",
    "    return scores\n",
    "\n",
    "def panmixia(selected_parents, total_offspring):\n",
    "    \"\"\" Handles the random crossing for us ; heuristic!\n",
    "\n",
    "    selected_parents ( n , m , d )\n",
    "    \n",
    "    \"\"\"\n",
    "    n, m, d = selected_parents.shape\n",
    "    offspring_target = total_offspring\n",
    "    offspring_list = []\n",
    "\n",
    "    while len(offspring_list) < offspring_target:\n",
    "        # Randomly pick two parents without replacement\n",
    "        parents_indices = np.random.choice(n, size=2, replace=False)\n",
    "        parent1, parent2 = selected_parents[parents_indices]\n",
    "\n",
    "        # Simulate random recombination for each marker\n",
    "        offspring = np.zeros((m, d), dtype=parent1.dtype)\n",
    "        for i in range(m):\n",
    "            # Randomly choose one allele from each parent for each marker\n",
    "            for j in range(d):\n",
    "                parent_allele = np.random.choice([parent1[i, j], parent2[i, j]])\n",
    "                offspring[i, j] = parent_allele\n",
    "\n",
    "        # Add the new offspring to the offspring list\n",
    "        offspring_list.append(offspring)\n",
    "\n",
    "    # Convert offspring list to a numpy array with shape (offspring_target, m, d)\n",
    "    offspring_array = np.array(offspring_list)\n",
    "    return offspring_array\n",
    "\n",
    "\n",
    "def scores2parents(scores,K):\n",
    "    \"\"\"\n",
    "    hint: use output from calculate_scores\n",
    "    \"\"\"\n",
    "    # Specify the number of top values you want (K)\n",
    "    K = 5\n",
    "\n",
    "    # Get the indices that would sort the array\n",
    "    sorted_indices = np.argsort(scores)\n",
    "\n",
    "    # Take the last K indices of the sorted indices array\n",
    "    top_k_indices = sorted_indices[-K:]\n",
    "\n",
    "    # Since argsort returns indices in ascending order, reverse to get the top values\n",
    "    top_k_indices = top_k_indices[::-1]\n",
    "\n",
    "    print(\"Indices of top K values:\", top_k_indices)\n",
    "    print(\"Top K values:\", scores[top_k_indices])\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "def select_parents(policy, total_parents):\n",
    "    \"\"\"\n",
    "        input: Policy from actor ( score or metric value for each individual )\n",
    "        returns : index of parents to be included in random_crosses for next step of breeding program\n",
    "    \"\"\"\n",
    "    # Use numpy's argsort function to get the indices of the top 'total_parents' values\n",
    "    indices = np.argsort(policy)[-total_parents:]\n",
    "    values = policy[indices]\n",
    "    return values,indices\n",
    "\n",
    "def printshape(message , arr):\n",
    "    print(f'{message} {arr.shape}')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def score2hist(score, title='population score distribution'):\n",
    "    #e.g. (3,50) array\n",
    "\n",
    "    # Assuming 'data' is your (3,50) array\n",
    "    data = score\n",
    "\n",
    "    # Plot KDE for each row in the data\n",
    "    for i in range(data.shape[0]):\n",
    "        kde = gaussian_kde(data[i])\n",
    "        dist_space = np.linspace(min(data[i]), max(data[i]), 100)\n",
    "        plt.plot(dist_space, kde(dist_space), label=f'Distribution {i+1}')\n",
    "\n",
    "    # Adding labels and legend\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "number_individuals = 50  # Replace with your actual number of individuals\n",
    "number_markers = 100     # Replace with your actual number of markers\n",
    "ploidy = 2              # Replace with your actual ploidy level\n",
    "batch_size = 3\n",
    "initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "marker_strength = np.array(genetic_map_df['Yield'])\n",
    "fraction_selection = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def init_program():\n",
    "    number_individuals = 50  # Replace with your actual number of individuals\n",
    "    number_markers = 100     # Replace with your actual number of markers\n",
    "    ploidy = 2               # Replace with your actual ploidy level\n",
    "    batch_size = 3\n",
    "    initial_population = create_fake_population(batch_size, number_individuals, number_markers, ploidy)\n",
    "    genetic_map_df = create_fake_geneticmap(number_markers)\n",
    "    marker_strength = np.array(genetic_map_df['Yield'])\n",
    "    fraction_selection = 10\n",
    "\n",
    "    # Convert marker_strength to a PyTorch tensor\n",
    "    marker_strength_tensor = torch.tensor(marker_strength, dtype=torch.float32)\n",
    "\n",
    "    # Score the initial population\n",
    "    initial_score = np.array([calculate_scores(torch.tensor(x, dtype=torch.float32), marker_strength_tensor).numpy() for x in initial_population])\n",
    "\n",
    "    return initial_population, initial_score, genetic_map_df, marker_strength\n",
    "\n",
    "# Make sure the calculate_scores function is defined correctly as shown in the previous response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_sum() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#select random half of individuals in each pop\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     selected_parents \u001b[38;5;241m=\u001b[39m current_population[:,:\u001b[38;5;241m25\u001b[39m,:,:]\n\u001b[0;32m---> 11\u001b[0m     selected_parents_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([calculate_scores(x, marker_strength) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m selected_parents])\n\u001b[1;32m     12\u001b[0m     new_pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([panmixia(x, total_offspring\u001b[38;5;241m=\u001b[39minitial_population\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m selected_parents])\n\u001b[1;32m     13\u001b[0m     new_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([calculate_scores(x, marker_strength) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m new_pop])\n",
      "Cell \u001b[0;32mIn[75], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#select random half of individuals in each pop\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     selected_parents \u001b[38;5;241m=\u001b[39m current_population[:,:\u001b[38;5;241m25\u001b[39m,:,:]\n\u001b[0;32m---> 11\u001b[0m     selected_parents_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mcalculate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker_strength\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m selected_parents])\n\u001b[1;32m     12\u001b[0m     new_pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([panmixia(x, total_offspring\u001b[38;5;241m=\u001b[39minitial_population\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m selected_parents])\n\u001b[1;32m     13\u001b[0m     new_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([calculate_scores(x, marker_strength) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m new_pop])\n",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m, in \u001b[0;36mcalculate_scores\u001b[0;34m(offspring, marker_tensor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_scores\u001b[39m(offspring, marker_tensor):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Sum the contributions from both sets of chromosomes (ploidy)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     summed_offspring \u001b[38;5;241m=\u001b[39m \u001b[43moffspring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will sum across the ploidy dimension\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Perform the dot product between the marker_tensor and the summed_offspring\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# We need to unsqueeze the marker_tensor to perform batch matrix multiplication\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     marker_tensor_unsqueezed \u001b[38;5;241m=\u001b[39m marker_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: _sum() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "#random selection baseline\n",
    "\n",
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "current_population = initial_population\n",
    "current_score = initial_score\n",
    "\n",
    "for _ in range(5):\n",
    "    #select random half of individuals in each pop\n",
    "    selected_parents = current_population[:,:25,:,:]\n",
    "    selected_parents_score = np.array([calculate_scores(x, marker_strength) for x in selected_parents])\n",
    "    new_pop = np.array([panmixia(x, total_offspring=initial_population.shape[1]) for x in selected_parents])\n",
    "    new_score = np.array([calculate_scores(x, marker_strength) for x in new_pop])\n",
    "    \n",
    "    current_population = new_pop\n",
    "    current_score = new_score\n",
    "    score2hist(selected_parents_score, title='selected parents scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#select top half of individuals in each pop\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     truncation \u001b[38;5;241m=\u001b[39m [select_parents(x,\u001b[38;5;28mint\u001b[39m(initial_population\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m current_score]\n\u001b[1;32m     12\u001b[0m     parent_index \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m truncation]\n\u001b[1;32m     13\u001b[0m     parent_metric \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m truncation]\n",
      "Cell \u001b[0;32mIn[76], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#select top half of individuals in each pop\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     truncation \u001b[38;5;241m=\u001b[39m [\u001b[43mselect_parents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minitial_population\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m current_score]\n\u001b[1;32m     12\u001b[0m     parent_index \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m truncation]\n\u001b[1;32m     13\u001b[0m     parent_metric \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m truncation]\n",
      "Cell \u001b[0;32mIn[6], line 145\u001b[0m, in \u001b[0;36mselect_parents\u001b[0;34m(policy, total_parents)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Use numpy's argsort function to get the indices of the top 'total_parents' values\u001b[39;00m\n\u001b[1;32m    144\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(policy)[\u001b[38;5;241m-\u001b[39mtotal_parents:]\n\u001b[0;32m--> 145\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values,indices\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#truncation selection baseline\n",
    "\n",
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n",
    "\n",
    "current_population = initial_population\n",
    "current_score = initial_score\n",
    "\n",
    "frames = []\n",
    "for _ in range(5):\n",
    "    #select top half of individuals in each pop\n",
    "    truncation = [select_parents(x,int(initial_population.shape[1]/2)) for x in current_score]\n",
    "    parent_index = [x[1] for x in truncation]\n",
    "    parent_metric = [x[0] for x in truncation]\n",
    "    parent_pop = np.array([x[y] for x,y in zip(current_population, parent_index)])    \n",
    "    new_pop = np.array([panmixia(x, total_offspring=initial_population.shape[1]) for x in parent_pop])\n",
    "    new_score = np.array([calculate_scores(x, marker_strength) for x in new_pop])\n",
    "    \n",
    "    current_population = new_pop\n",
    "    current_score = new_score\n",
    "    score2hist(current_score)\n",
    "    frames.append(current_score)\n",
    "\n",
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_normal_\n",
    "\n",
    "class ActorModel(nn.Module):\n",
    "    def __init__(self, num_individual, num_markers, ploidy, use_skip_connection=False):\n",
    "        super(ActorModel, self).__init__()\n",
    "        \n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        # Flatten layers for population and phenotype inputs\n",
    "        self.flatten_population = nn.Flatten()\n",
    "        self.flatten_phenotype = nn.Flatten()\n",
    "        \n",
    "        # Combined input size calculation\n",
    "        combined_input_size = num_individual * num_markers * ploidy + num_individual\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden1 = nn.Linear(combined_input_size, 64)\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.output = nn.Linear(64, num_individual)\n",
    "        \n",
    "        # Define the transformation layer for skip connection\n",
    "        if use_skip_connection:\n",
    "            self.phenotype_transform = nn.Linear(num_individual, 64)\n",
    "        \n",
    "        # Initialize weights using He initialization\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, population_input, phenotype_input):\n",
    "        # Flatten inputs\n",
    "        flat_population = self.flatten_population(population_input)\n",
    "        flat_phenotype = self.flatten_phenotype(phenotype_input)\n",
    "        \n",
    "        # Combine inputs\n",
    "        combined = torch.cat([flat_population, flat_phenotype], dim=1)\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        hidden1 = F.relu(self.hidden1(combined))\n",
    "        hidden2 = F.relu(self.hidden2(hidden1))\n",
    "        \n",
    "        # Check if skip connection is to be used\n",
    "        if self.use_skip_connection:\n",
    "            phenotype_transformed = F.relu(self.phenotype_transform(flat_phenotype))\n",
    "            skip_connection = hidden2 + phenotype_transformed\n",
    "            output = F.softmax(self.output(skip_connection), dim=1)\n",
    "        else:\n",
    "            output = F.softmax(self.output(hidden2), dim=1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 100, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_population.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_population, initial_score, genetic_map_df, marker_strength = init_program()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = ActorModel(num_individual=initial_population.shape[1], num_markers = initial_population.shape[2], ploidy = initial_population.shape[3])\n",
    "\n",
    "population_tensor = torch.from_numpy(initial_population).float()\n",
    "score_tensor = torch.from_numpy(initial_score).float()\n",
    "score_tensor = score_tensor[:,0,:]\n",
    "marker_tensor = torch.from_numpy(marker_strength).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the prediction\n",
    "with torch.no_grad():  # This will disable gradient computation during inference, which reduces memory usage\n",
    "    prediction = a(population_tensor, score_tensor)\n",
    "\n",
    "# Sample 25 individuals from each population\n",
    "num_samples = 25\n",
    "samples = torch.multinomial(prediction, num_samples, replacement=True)\n",
    "\n",
    "# Create a tensor for the batch dimension which corresponds to each population\n",
    "batch_indices = torch.arange(population_tensor.size(0)).unsqueeze(1).expand_as(samples)\n",
    "\n",
    "# Use the batch_indices and samples to index into the initial_population tensor\n",
    "selected_parents = population_tensor[batch_indices, samples]\n",
    "\n",
    "# selected_parents now contains the 25 parents from each population with shape (3, 25, num_markers, ploidy)\n",
    "\n",
    "# NEXT perform crossing over by randomly selecting 2 parents and mating them until we have 50 individuals per population\n",
    "# return: 50 offspring per population (3, 50(new combinations based on selected_parents), num_markers, ploidy)\n",
    "offspring_geno = crossover(selected_parents)\n",
    "offspring_score = calculate_scores(offspring_geno, marker_tensor)\n",
    "\n",
    "# Calculate the mean of each array along axis 1\n",
    "offspring_score_mean = offspring_score.mean(dim=1, keepdim=True)\n",
    "score_tensor_mean = score_tensor.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Subtract the offspring_score mean from the score_tensor mean\n",
    "result = offspring_score_mean - score_tensor_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offspring_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_702377/3952986283.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  offspring_score = torch.tensor(offspring_score, dtype=torch.float32)\n",
      "/tmp/ipykernel_702377/3952986283.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score_tensor = torch.tensor(score_tensor, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0686],\n",
       "        [-1.9543],\n",
       "        [-0.2971]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_scores(population_tensor, marker_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-31.0000, -28.3333, -35.6667, -29.3333, -28.6667, -26.0000, -33.3333,\n",
       "         -32.6667, -31.0000, -26.0000, -30.6667, -25.0000, -36.0000, -32.0000,\n",
       "         -24.0000, -32.3333, -32.0000, -34.3333, -26.6667, -30.6667, -33.6667,\n",
       "         -32.3333, -27.6667, -27.3333, -28.0000, -23.6667, -32.0000, -29.6667,\n",
       "         -26.6667, -38.0000, -22.6667, -32.6667, -32.6667, -29.6667, -32.6667,\n",
       "         -29.0000, -32.0000, -31.6667, -32.3333, -28.6667, -28.3333, -30.0000,\n",
       "         -31.6667, -33.0000, -29.0000, -33.6667, -31.6667, -30.0000, -32.6667,\n",
       "         -33.6667],\n",
       "        [-28.0000, -39.3333, -36.6667, -30.6667, -25.6667, -30.3333, -34.0000,\n",
       "         -32.3333, -38.0000, -34.0000, -30.3333, -33.0000, -26.0000, -25.0000,\n",
       "         -28.6667, -30.0000, -34.0000, -32.0000, -36.6667, -25.6667, -25.3333,\n",
       "         -24.0000, -34.3333, -25.0000, -27.6667, -26.6667, -32.6667, -25.0000,\n",
       "         -31.0000, -21.3333, -35.0000, -33.6667, -28.3333, -33.6667, -29.0000,\n",
       "         -23.6667, -30.3333, -26.6667, -23.0000, -28.0000, -34.6667, -27.3333,\n",
       "         -30.0000, -31.3333, -31.0000, -37.3333, -30.0000, -28.0000, -22.6667,\n",
       "         -30.3333],\n",
       "        [-30.3333, -26.0000, -34.3333, -27.3333, -24.6667, -30.6667, -26.0000,\n",
       "         -29.6667, -35.6667, -31.6667, -29.0000, -33.0000, -38.0000, -30.0000,\n",
       "         -27.3333, -29.3333, -27.6667, -24.6667, -27.0000, -30.0000, -29.3333,\n",
       "         -26.6667, -34.3333, -33.6667, -35.6667, -32.6667, -39.6667, -25.6667,\n",
       "         -27.0000, -31.0000, -31.0000, -25.6667, -33.0000, -35.0000, -28.3333,\n",
       "         -26.6667, -27.0000, -32.3333, -17.3333, -27.6667, -28.3333, -32.0000,\n",
       "         -30.6667, -24.3333, -36.3333, -37.6667, -32.0000, -27.6667, -22.6667,\n",
       "         -34.3333]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50, 100, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offspring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parents):\n",
    "    num_offspring_per_population = 50\n",
    "    num_populations, num_parents, num_markers, ploidy = parents.shape\n",
    "    offspring = torch.empty((num_populations, num_offspring_per_population, num_markers, ploidy), dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_populations):\n",
    "        for j in range(num_offspring_per_population):\n",
    "            # Randomly select two parents\n",
    "            parent_indices = torch.randperm(num_parents)[:2]\n",
    "            parent1 = parents[i, parent_indices[0]]\n",
    "            parent2 = parents[i, parent_indices[1]]\n",
    "\n",
    "            # Perform single crossover\n",
    "            crossover_point = torch.randint(low=1, high=num_markers, size=(1,)).item()\n",
    "            child1 = torch.cat((parent1[:crossover_point, :], parent2[crossover_point:, :]), dim=0)\n",
    "            child2 = torch.cat((parent2[:crossover_point, :], parent1[crossover_point:, :]), dim=0)\n",
    "\n",
    "            # Randomly select one of the two possible offspring\n",
    "            offspring[i, j] = child1 if torch.rand(1).item() < 0.5 else child2\n",
    "\n",
    "    return offspring\n",
    "\n",
    "# Assuming selected_parents is the tensor containing the 25 selected parents from each population\n",
    "# with shape (3, 25, num_markers, ploidy)\n",
    "offspring = crossover(selected_parents)\n",
    "\n",
    "# offspring now contains 50 offspring for each population with shape (3, 50, num_markers, ploidy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(offspring, marker_tensor):\n",
    "    # Sum the contributions from both sets of chromosomes (ploidy)\n",
    "    summed_offspring = offspring.sum(dim=-1)  # This will sum across the ploidy dimension\n",
    "    \n",
    "    # Perform the dot product between the marker_tensor and the summed_offspring\n",
    "    # We need to unsqueeze the marker_tensor to perform batch matrix multiplication\n",
    "    marker_tensor_unsqueezed = marker_tensor.unsqueeze(0).unsqueeze(-1)\n",
    "    \n",
    "    # Perform batch matrix multiplication\n",
    "    scores = torch.matmul(summed_offspring, marker_tensor_unsqueezed)\n",
    "    \n",
    "    # Remove the last dimension and squeeze the result to get the final scores\n",
    "    scores = scores.squeeze(-1)\n",
    "    \n",
    "    return scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
